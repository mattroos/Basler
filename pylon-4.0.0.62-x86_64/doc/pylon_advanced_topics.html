<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>Pylon: Programmer&#39;s Guide and API Reference for pylon for Linux</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
<link href="modified_doxygen-linux.css" rel="stylesheet" type="text/css"/>
<div><img src="Banner_PG.png" /></div>
</head>
<!-- Generated by Doxygen 1.8.6 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="index.html">Programmer's Guide and API Reference for pylon for Linux</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Advanced Topics </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><ul>
<li><a class="el" href="pylon_advanced_topics.html#architecture">Architecture of pylon</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#buildingapplications">Settings for Building Applications with pylon</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#debugging">Debugging pylon Applications Using GigE Cameras</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#enumerating_and_creating">Enumerating and Creating pylon Devices</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#grab_strategies">Grab Strategies</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#hi_pnp_ref">Getting Informed About Camera Device Removal</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#hi_parsingchunks_ref">Accessing Chunk Features</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#hi_grabbingevents_ref">Handling Camera Events</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#GettingInformedAboutParameterChanges">Getting Informed About Parameter Changes</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#bindingrules">How to Control the Location of the Camera Description Files Used by pylon</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#MulticastGrabbing">Receiving Image Data</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#loadsavecamerafeatures">Saving and Restoring Camera Features to/from Files</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#shadingfileio">Transferring Shading Data to the Camera</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#waitingformultiple">Waiting for Multiple Events</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#highperformanceapps">Application Settings for High Performance</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#programmers_guide_low_level_api">Programming Using the pylon Low Level API</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#migration_to_usb">Migrating Existing Code for Using USB Camera Devices</a></li>
</ul>
<p>The advanced topics section can be consulted if more information about special use cases is required.</p>
<h1><a class="anchor" id="architecture"></a>
Architecture of pylon</h1>
<p>This section gives a short introduction to the most important concepts of the pylon C++ API.</p>
<div class="image">
<img src="pylon3_0_cpp_api.png" alt="pylon3_0_cpp_api.png"/>
<div class="caption">
The pylon C++ API.</div></div>
 <h2><a class="anchor" id="TransportLayers"></a>
Transport Layers</h2>
<p>The term 'transport layer' is used as an abstraction for a physical interface such as IEEE 1394, GigE or Camera Link. For each of these interfaces, there are drivers providing access to camera devices. pylon currently includes three different transport layers: </p>
<ul>
<li>PylonGigE for Gigabit Ethernet cameras using the GigE Vision protocol </li>
<li>Pylon1394 for IIDC 1394 compliant cameras (not available on Linux platforms) </li>
<li>PylonUsb for USB3 Vision compliant cameras </li>
<li>PylonCLSer for Camera Link cameras using the CL serial interface (limited to camera configuration only, not available on Linux platforms)</li>
</ul>
<p><a class="el" href="struct_pylon_1_1_i_transport_layer.html">Transport Layer objects</a> are <a class="el" href="class_pylon_1_1_c_tl_factory.html">device factories</a> and are used to: </p>
<ul>
<li>Discover devices (this process is also called device enumeration) </li>
<li>Create pylon Devices used to access camera devices </li>
<li>Destroy pylon Devices </li>
<li>Access transport layer specific parameters</li>
</ul>
<h2><a class="anchor" id="TransportLayerFactory"></a>
Transport Layer Factory</h2>
<p>An application program does not access transport layer implementations directly. The Transport Layer Factory is used to create Transport Layer objects, each of which represents a transport layer. Additionally, the <a class="el" href="class_pylon_1_1_c_tl_factory.html">Transport Layer Factory</a> can be used as a <a class="el" href="class_pylon_1_1_c_tl_factory.html">device factory</a> to create and destroy pylon Devices for all transport layers.</p>
<h2><a class="anchor" id="CameraObjects"></a>
Low Level API pylon Devices</h2>
<p>In pylon, physical camera devices are represented by <a class="el" href="struct_pylon_1_1_i_pylon_device.html">pylon Devices</a>. pylon Devices are only directly used when programming against the <a class="el" href="pylon_advanced_topics.html#programmers_guide_low_level_api">Low Level API</a>.</p>
<h2><a class="anchor" id="InstantCameraObjects"></a>
Instant Camera Classes</h2>
<p>An <a class="el" href="class_pylon_1_1_c_instant_camera.html">Instant Camera </a> provides convenient access to a camera device while being highly customizable. It allows to grab images with few lines of code providing instant access to grabbed images from a camera device. Internally a pylon Device is used. A pylon Device needs to be created and attached to the Instant Camera object for operation. Additional <a class="el" href="pylon_programmingguide.html#hi_typesof_instantcameras">Device Specific Instant Camera</a> classes provide more convenient access to the parameters of the camera. Furthermore, the <a class="el" href="pylon_programmingguide.html#hi_instant_camera_array">Instant Camera Array classes</a> eases programming for image grabbing from multiple camera devices.</p>
<h2><a class="anchor" id="GenApiNodeMaps"></a>
GenApi Node Maps</h2>
<p>For camera configuration and for accessing other parameters, the pylon API uses the technologies defined by the GenICam standard hosted by the European Machine Vision Association (EMVA). The GenICam specification (<a href="http://www.GenICam.org">http://www.GenICam.org</a>) defines a format for camera description files. These files describe the configuration interface of <a class="el" href="namespace_gen_i_cam.html" title="Contains definitions of GenICam types and exceptions. ">GenICam</a> compliant cameras. The description files are written in XML (eXtensible Markup Language) and describe camera registers, their interdependencies, and all other information needed to access high-level features such as <code>Gain</code>, <code>Exposure</code> <code>Time</code>, or <code>Image</code> <code>Format</code> by means of low level register read and write operations.</p>
<p>The elements of a camera description file are represented as software objects called Nodes. For example, a node can represent a single camera register, a camera parameter such as Gain, a set of available parameter values, etc. Each node implements the <code><a class="el" href="struct_gen_api_1_1_i_node.html" title="Interface common to all nodes. ">GenApi::INode</a></code> interface.</p>
<p>The nodes are linked together by different relationships as explained in the GenApi standard document available at www.GenICam.org. The complete set of nodes is stored in a data structure called node map. At runtime, a node map is instantiated from an XML description.</p>
<p>Using the code generators provided by GenICam's GenApi module, a programming interface is created from a camera description file. This interface is represented as a parameter class, that has a member for each camera parameter. The members are references (or handles) to the <a class="el" href="namespace_gen_api.html" title="Contains definitions of the types of GenICam GenApi modules. ">GenApi</a> Nodes representing the parameters. Such a parameter class can represent the parameters of a camera device for a certain transport layer, e.g. <a class="el" href="class_basler___gig_e_camera_1_1_c_gig_e_camera___params.html">GigE</a>.</p>
<p>In pylon, node maps are not only used to represent camera device parameters. Parameters of other pylon objects such as Transport Layer objects or the Image Format Converter are also exposed via GenApi node maps.</p>
<p>Examples:</p>
<ul>
<li>The <code><a class="el" href="class_pylon_1_1_c_instant_camera.html" title="Provides convenient access to a camera device. ">Pylon::CInstantCamera</a></code> class has the <code><a class="el" href="class_pylon_1_1_c_instant_camera.html#a3227195969200a52200364bf31e9c586" title="Provides access to the node map of the camera device. ">Pylon::CInstantCamera::GetNodeMap()</a></code> method, which returns the node map containing all GenApi nodes representing the whole set of camera parameters. </li>
<li>The <code><a class="el" href="class_pylon_1_1_c_image_format_converter.html#a78b2bec7fb5867f833b91774b55b7a13" title="Provides access to the node map of the format converter. ">Pylon::CImageFormatConverter::GetNodeMap()</a></code> method is used to access the Image Format Converter's parameters.</li>
</ul>
<h2><a class="anchor" id="hi_image_handling_architecture"></a>
Image Handling Support</h2>
<p>Besides the Instant Camera classes used for grabbing images pylon offers additional <a class="el" href="group___pylon___image_handling_support.html">Image Handling Support</a> support for handling grabbed images. There are an image class, an image format converter, and the loading and saving of images.</p>
<h2><a class="anchor" id="LowLevelAPIObjects"></a>
Low Level API</h2>
<dl class="section note"><dt>Note</dt><dd>The Low Level API should only be used for existing applications and for rare highly advanced use cases, that cannot be covered using the Instant Camera classes. Please use the Instant Camera classes instead of the Low Level API.</dd></dl>
<h3><a class="anchor" id="LowLevelCameraObjects"></a>
Camera Classes</h3>
<p>A Low Level API camera object wraps a <a class="el" href="struct_pylon_1_1_i_pylon_device.html">pylon Device</a> and provides more convenient access to the parameters of the camera, the stream grabber, the event grabber, and Transport Layer using GenApi parameter classes. The low level camera classes are replaced by the <a class="el" href="pylon_programmingguide.html#hi_typesof_instantcameras">Device Specific Instant Camera</a> classes.</p>
<h3><a class="anchor" id="StreamGrabbers"></a>
Stream Grabbers</h3>
<p>The pylon architecture allows a camera object to deliver one or more streams of image data. To grab images from a stream, a Stream Grabber object is required. Stream Grabber objects cannot be created directly by an application. They are managed by Camera objects, which create and pass out Stream Grabbers. All Stream Grabbers implement the <a class="el" href="struct_pylon_1_1_i_stream_grabber.html" title="Low Level API: Interface to an (input) data stream. ">Pylon::IStreamGrabber</a> interface. This means that for all transport layers, images are grabbed from streams in exactly the same way. More details about grabbing images are described below in the <a class="el" href="low_level_api.html#grabbingimages">Grabbing Images</a> section for the Low Level API.</p>
<h3><a class="anchor" id="EventGrabbers"></a>
Event Grabbers</h3>
<p>Basler GigE Vision cameras can send event messages. Event Grabber objects are used to receive event messages. How to retrieve and process event messages is described below in the <a class="el" href="low_level_api.html#grabbingevents">Handling Camera Events</a> section for the Low Level API.</p>
<h3><a class="anchor" id="ChunkParsers"></a>
Chunk Parsers</h3>
<p>If the so-called Chunk Mode is activated, Basler Cameras can send additional information appended to the image data. When in Chunk Mode, the camera sends an extended data stream including the image data combined with added information such as a frame number or a time stamp. The extended data stream is self-descriptive. pylon Chunk Parser objects are used for parsing the extended data stream and for providing access to the added information. Chunk Parser objects are described in the <a class="el" href="low_level_api.html#parsingchunks">Chunk Parser: Accessing Chunk Features</a> section for the Low Level API.</p>
<h1><a class="anchor" id="buildingapplications"></a>
Settings for Building Applications with pylon</h1>
<p>As described in the INSTALL document and in the <a class="el" href="pylon_programmingguide.html#runningapplications_brief">Common Settings for Running Applications with pylon</a> section, the following environment variables must be exported when building pylon applications:</p>
<ul>
<li>PYLON_ROOT </li>
<li>GENICAM_ROOT_V2_3</li>
</ul>
<p>To compile a pylon-based application, you can use the following Makefile snippet as a basis for the compiler and linker settings: </p>
<div class="fragment"><div class="line">CPPFLAGS        := -I$(GENICAM_ROOT_V2_3)/library/CPP/include \</div>
<div class="line">                   -I$(PYLON_ROOT)/include</div>
<div class="line">LDFLAGS         := -L$(PYLON_ROOT)/lib \</div>
<div class="line">                   -L$(GENICAM_ROOT_V2_3)/bin/@TARGET_NAME@ \</div>
<div class="line">                   -L$(GENICAM_ROOT_V2_3)/bin/@TARGET_NAME@/GenApi/Generic \</div>
<div class="line">                   -Wl,-E</div>
<div class="line">LIBS            := -lpylonbase -lGenApi@GENICAM_LIB_SUFFIX@ -lGCBase@GENICAM_LIB_SUFFIX@ \</div>
<div class="line">                   -lLog@GENICAM_LIB_SUFFIX@ -lMathParser@GENICAM_LIB_SUFFIX@ \</div>
<div class="line">                   -lXerces-C@XERCES_LIB_SUFFIX@ -llog4cpp@GENICAM_LIB_SUFFIX@</div>
</div><!-- fragment --><p>where <code>@TARGET_NAME@</code> must be set to: </p>
<ul>
<li><code>Linux32_i86</code> when building for x86 </li>
<li><code>Linux64_x64</code> when building for x86 64bit </li>
<li><code>Linux32_ARM</code> when building for ARM</li>
</ul>
<p>and <code>@GENICAM_LIB_SUFFIX@</code> must be set to: </p>
<ul>
<li><code>_gcc40_v2_3</code> when building for x86 (32bit and 64bit) </li>
<li><code>_gcc43_v2_3</code> when building for ARM</li>
</ul>
<p>and <code>@XERCES_LIB_SUFFIX@</code> must be set to: </p>
<ul>
<li><code>_gcc40_v2_7_1</code> when building for x86 (32bit and 64bit) </li>
<li><code>_gcc43_v2_7</code> when building for ARM</li>
</ul>
<dl class="section attention"><dt>Attention</dt><dd>Executables using the pylon API <b>must</b> be linked using the <code>-Wl,-E</code> compiler option to ensure that run-time type information for pylon-defined types is processed properly, which is in particular essential for proper exception handling.</dd></dl>
<h1><a class="anchor" id="debugging"></a>
Debugging pylon Applications Using GigE Cameras</h1>
<p>When debugging a pylon application using GigE cameras you may encounter heartbeat timeouts. The application must send special network packets to the camera in defined intervals. If the camera doesn't receive these heartbeats it will consider the connection as broken and won't accept any commands from the application.</p>
<p>When you run your application pylon will normally generate these heartbeats. When you set a breakpoint in your application and the breakpoint is hit, the debugger will suspend all threads including the one sending the heartbeats. So when you debug your application and single step through your code no heartbeats are sent to the camera.</p>
<p>To work around this you have to extend the heartbeat timeout during development. You can do this by setting an environment variable named PYLON_GIGE_HEARTBEAT which will instruct pylon to set the heartbeat interval when opening the camera or you can set the heartbeat timeout value named "HeartbeatTimeout" of the camera transport layer in your code. To set the environment variable set an environment variable named PYLON_GIGE_HEARTBEAT and set its value to the desired timeout in milliseconds. To set the Heartbeat timeout in code set the value on the <code>HeartbeatTimeout</code> node of the transport layer: </p>
<div class="fragment"><div class="line"><span class="comment">// retrieve the heartbeat node from the transport layer node map</span></div>
<div class="line"><a class="code" href="class_gen_api_1_1_c_pointer.html">GenApi::CIntegerPtr</a> pHeartbeat = pCamera-&gt;GetTLNodeMap()-&gt;GetNode(<span class="stringliteral">&quot;HeartbeatTimeout&quot;</span>);</div>
<div class="line"><span class="comment">// set heartbeat to 600 seconds. (Note: Only GigE cameras have a &quot;HeatbeatTimeout&quot; node)</span></div>
<div class="line"><span class="keywordflow">if</span> (pHeartbeat != NULL ) pHearbeat-&gt;SetValue(600*1000);</div>
</div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>When you set the heartbeat to a high value and stop your application without closing the device properly by calling the Close function you won't be able to open the camera again and will receive an error stating the device is currently in use. This can happen if you stop your application using the debugger. To open the camera again you must either wait until the timeout elapses or disconnect the network cable from the camera.</dd>
<dd>
The pylon GigE transport layer automatically sets the heartbeat timeout to 5 minutes when creating a device if running under a debugger. This can be overridden by setting the PYLON_GIGE_HEARTBEAT environment variable. We recommend not to rely on the default mechanism but to explicitly specify the heartbeat timeout by setting the environment variable or by setting an appropriate heartbeat timeout in the application.</dd></dl>
<h1><a class="anchor" id="enumerating_and_creating"></a>
Enumerating and Creating pylon Devices</h1>
<p>pylon offers two ways to enumerate and create pylon Devices. The first approach uses the Transport Layer Factory to enumerate cameras across multiple transport layers. The second approach lets a Transport Layer object enumerate and create pylon Devices for a specific transport layer. Before describing the different enumeration schemes, the terms Device Class and Device Info object are introduced.</p>
<h2><a class="anchor" id="DeviceClasses"></a>
Device Classes</h2>
<p>Each transport layer can create a specific type of pylon Device. For example, the PylonGigE transport layer will create pylon Devices representing GigE Vision cameras. Each type of device is associated with a unique identifier string called Device Class. The device class identifier can be found in the <a class="el" href="_device_class_8h.html" title="Device class definitions. ">DeviceClass.h</a> header file.</p>
<h2><a class="anchor" id="DeviceInfoObjects"></a>
Device Info Objects</h2>
<p>The device enumeration procedure returns a list of Device Info objects. The base class for Device Info objects is <code><a class="el" href="class_pylon_1_1_c_device_info.html" title="Holds information about an enumerated device. ">Pylon::CDeviceInfo</a></code>. A Device Info object uniquely describes a camera device. Device Info objects are used by a Transport Layer and the Transport Layer Factory to create camera objects representing the device described by the Device Info objects.</p>
<p>A <code><a class="el" href="class_pylon_1_1_c_device_info.html" title="Holds information about an enumerated device. ">Pylon::CDeviceInfo</a></code> object stores a set of string properties. The data type of the values is <code><a class="el" href="namespace_pylon.html#a243b4b164b22d387ffd02a9ed20f15b9" title="Pylon&#39;s string definition. ">Pylon::String_t</a></code>. The following properties are available for all Device Info Objects:</p>
<table  border="1" class="table" frame="void" cellspacing="6" cellpadding="7">
<tr>
<th>Name</th><th>Description </th></tr>
<tr>
<td>FriendlyName </td><td>A human readable name for the device (e.g. the camera's model name). Friendly names are not unique.  </td></tr>
<tr>
<td>FullName </td><td>A unique identifier for the device. No two devices will have the same full name.  </td></tr>
<tr>
<td>VendorName </td><td>The name of the vendor.  </td></tr>
<tr>
<td>DeviceClass </td><td>Each transport layer can create a specific type (or class) of camera devices (e.g. IIDC 1394 or GigE Vision devices). The device types are identified by the Device Class property. </td></tr>
<tr>
<td>SerialNumber </td><td>The device's serial number. The availability of the device serial number is not guaranteed during the enumeration process, so the Serial Number Property may be undefined.  </td></tr>
<tr>
<td>UserDefinedName </td><td>For some device classes, it is possible to assign a user defined name to a camera device. The value of this property is not necessarily unique.  </td></tr>
<tr>
<td>DeviceFactory </td><td>The unique full name of the Transport Layer object that can create the device. </td></tr>
</table>
<p>In addition, specific transport layers will require additional properties. These properties can be accessed in a generic way by using the <code><a class="el" href="struct_pylon_1_1_i_properties.html" title="interface for a property container ">Pylon::IProperties</a></code> interface.</p>
<p>A more comfortable way is downcasting a Device Info object to the concrete class. This is illustrated in the following example, which prints out the IP address of a GigE Device Info object: </p>
<div class="fragment"><div class="line">CBaslerGigECamera::DeviceInfo_t&amp; GigEDeviceInfo =</div>
<div class="line">  <span class="keyword">static_cast&lt;</span>CBaslerGigECamera::DeviceInfo_t&amp;<span class="keyword">&gt;</span>(DeviceInfo);</div>
<div class="line">cout &lt;&lt; GigEDeviceInfo.GetIpAddress() &lt;&lt; endl;</div>
</div><!-- fragment --><h2><a class="anchor" id="UsingTlFactory"></a>
Using the Transport Layer Factory for Enumerating Cameras</h2>
<p>The <code><a class="el" href="class_pylon_1_1_c_tl_factory.html#a9a66b37caea9bbd0a50cf377ba4ed94a" title="returns a list of available devices, see IDeviceFactory for more information ">Pylon::CTlFactory::EnumerateDevices()</a></code> method is used to retrieve a list of all available devices, regardless of which transport layer is used to access the device. The list contains Device Info objects that must be used for creating Camera objects.</p>
<p>The returned lists are of the <code><a class="el" href="namespace_pylon.html#a7df1a09a012dcec35092f3a732101af7" title="STL std::vector like container for Pylon::CDeviceInfo objects. ">Pylon::DeviceInfoList_t</a></code> type and are used similarly to the Standard Template Library (STL) <code>std::vector</code> class.</p>
<p>The following example prints out the unique names of all connected devices: </p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_pylon_includes_8h.html">pylon/PylonIncludes.h</a>&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;ostream&gt;</span></div>
<div class="line"><span class="keyword">using namespace </span>Pylon;</div>
<div class="line"><span class="keyword">using namespace </span>std;</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main()</div>
<div class="line">{</div>
<div class="line">  <a class="code" href="class_pylon_1_1_pylon_auto_init_term.html">PylonAutoInitTerm</a> autoInitTerm;</div>
<div class="line"></div>
<div class="line">  <a class="code" href="class_pylon_1_1_c_tl_factory.html">CTlFactory</a>&amp; TlFactory = <a class="code" href="class_pylon_1_1_c_tl_factory.html#a1d3fbd0bb73b4acd88de7cff893554ab">CTlFactory::GetInstance</a>();</div>
<div class="line">  <a class="code" href="class_pylon_1_1_device_info_list.html">DeviceInfoList_t</a> lstDevices;</div>
<div class="line">  TlFactory.<a class="code" href="class_pylon_1_1_c_tl_factory.html#a9a66b37caea9bbd0a50cf377ba4ed94a">EnumerateDevices</a>( lstDevices );</div>
<div class="line">  <span class="keywordflow">if</span> ( ! lstDevices.empty() ) {</div>
<div class="line">    DeviceInfoList_t::const_iterator it;</div>
<div class="line">    <span class="keywordflow">for</span> ( it = lstDevices.begin(); it != lstDevices.end(); ++it )</div>
<div class="line">      cout &lt;&lt; it-&gt;GetFullName();</div>
<div class="line">  }</div>
<div class="line">  <span class="keywordflow">else</span></div>
<div class="line">    cerr &lt;&lt; <span class="stringliteral">&quot;No devices found!&quot;</span> &lt;&lt; endl;</div>
<div class="line"></div>
<div class="line">  <span class="keywordflow">return</span> 0;</div>
<div class="line">}</div>
</div><!-- fragment --><p>The Transport Layer Factory provides a Device Info object and can be used to create Camera objects. The following example illustrates how to create a Camera object for the first element in the device list: </p>
<div class="fragment"><div class="line">IPylonDevice *pDevice = TlFactory.<a class="code" href="class_pylon_1_1_c_tl_factory.html#a5bfdb71c0f2ffd0d86839b8f463c3c4d">CreateDevice</a>( lstDevices[0] );</div>
</div><!-- fragment --><dl class="section attention"><dt>Attention</dt><dd>Never call <code>free</code> or <code>delete</code> on a <code><a class="el" href="struct_pylon_1_1_i_pylon_device.html" title="Low Level API: Interface for camera objects. ">Pylon::IPylonDevice</a></code> pointer created by the Transport Layer Factory. Instead, use the <code><a class="el" href="class_pylon_1_1_c_tl_factory.html#ae1f2e7bcf55bf64162f356d4b749f5b6" title="destroys a device ">Pylon::CTlFactory::DestroyDevice()</a></code> method to delete an IPylonDevice pointer.</dd></dl>
<h2><a class="anchor" id="CreatingTls"></a>
Using the Transport Layer Factory to Create a Transport Layer</h2>
<p>A list of all available transport layers can be retrieved by calling the <code><a class="el" href="class_pylon_1_1_c_tl_factory.html#a3b33b78f5b02907830aff7c3d9649a4e" title="Retrieve a list of available transport layers. ">Pylon::CTlFactory::EnumerateTls()</a></code> method. This method fills a list with Transport Layer Info objects (<code><a class="el" href="class_pylon_1_1_c_tl_info.html" title="Class used for storing the result of the transport layer enumeration process. ">Pylon::CTlInfo</a></code>). The data structures are very similar to Device Info objects. Transport Layer Info objects are used as arguments for the <code><a class="el" href="class_pylon_1_1_c_tl_factory.html#a6ede1fda37619e7e20e42da42ed74968" title="Create a transport layer object from a TlInfo object. ">Pylon::CTlFactory::CreateTl()</a></code> method that creates Transport Layer objects. The method returns a pointer of the <code><a class="el" href="struct_pylon_1_1_i_transport_layer.html" title="The interface of Transport Layer objects. ">Pylon::ITransportLayer</a></code> type.</p>
<dl class="section attention"><dt>Attention</dt><dd>Never call <code>free</code> or <code>delete</code> on a ITransportLayer pointer created by the Transport Layer Factory. Instead, use the <code><a class="el" href="class_pylon_1_1_c_tl_factory.html#a0be3fff4a7434adecd20ea6fe9dd23d6" title="Destroys a transport layer object. ">Pylon::CTlFactory::ReleaseTl()</a></code> method to free Transport Layer objects.</dd></dl>
<h2><a class="anchor" id="UsingTlos"></a>
Using a Transport Layer Object for Enumerating Cameras</h2>
<p>Transport Layer objects can be used to enumerate all devices accessible by a specific transport layer. Transport Layer objects are created by the Transport Layer Factory. This is illustrated in the following example, which creates a Transport Layer object for the PylonGigE transport layer: </p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_pylon_includes_8h.html">pylon/PylonIncludes.h</a>&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_basler_gig_e_camera_8h.html">pylon/gige/BaslerGigECamera.h</a>&gt;</span></div>
<div class="line"><span class="keyword">using namespace </span>Pylon;</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main()</div>
<div class="line">{</div>
<div class="line">  <a class="code" href="class_pylon_1_1_pylon_auto_init_term.html">PylonAutoInitTerm</a> autoInitTerm;</div>
<div class="line"></div>
<div class="line">  <a class="code" href="class_pylon_1_1_c_tl_factory.html">CTlFactory</a>&amp; TlFactory = <a class="code" href="class_pylon_1_1_c_tl_factory.html#a1d3fbd0bb73b4acd88de7cff893554ab">CTlFactory::GetInstance</a>();</div>
<div class="line">  <a class="code" href="struct_pylon_1_1_i_transport_layer.html">ITransportLayer</a>* pTl</div>
<div class="line">    = TlFactory.<a class="code" href="class_pylon_1_1_c_tl_factory.html#a6ede1fda37619e7e20e42da42ed74968">CreateTl</a>( <a class="code" href="class_pylon_1_1_c_pylon_gig_e_camera_t.html#a40df47cda54f13e619478ee75936fe96">CBaslerGigECamera::DeviceClass</a>() );</div>
<div class="line"></div>
<div class="line">  <span class="keywordflow">return</span> 0;</div>
<div class="line">}</div>
</div><!-- fragment --><p>As described above, Transport Layer objects can also be created by passing in a Transport Layer Info object.</p>
<p>The Transport Layer Object is now used for enumerating all of the devices it can access: </p>
<div class="fragment"><div class="line"><a class="code" href="namespace_pylon.html#a7df1a09a012dcec35092f3a732101af7">DeviceInfoList_t</a> lstDevices;</div>
<div class="line">pTl-&gt;<a class="code" href="struct_pylon_1_1_i_device_factory.html#a7c9485beb3f38fc1c17929a46f6bb7a2">EnumerateDevices</a>( lstDevices );</div>
<div class="line"><span class="keywordflow">if</span> ( lstDevices.empty() ) {</div>
<div class="line">    cerr &lt;&lt;  <span class="stringliteral">&quot;No devices found&quot;</span> &lt;&lt; endl;</div>
<div class="line">    exit(1);</div>
<div class="line">}</div>
</div><!-- fragment --><p><code><a class="el" href="struct_pylon_1_1_i_device_factory.html#a7c9485beb3f38fc1c17929a46f6bb7a2" title="Retrieves a list of available devices. ">Pylon::ITransportLayer::EnumerateDevices</a></code> adds the discovered devices to the passed-in Device Info List.</p>
<p>The Transport Layer object is now used for creating a Camera object. In the following example, a Camera Object for the first enumerated camera device is created: </p>
<div class="fragment"><div class="line">IPylonDevice* pDevice = pTl-&gt;<a class="code" href="struct_pylon_1_1_i_device_factory.html#a9891f54248fa6dc0f7cab171044458c4">CreateDevice</a>( lstDevices[0] );</div>
</div><!-- fragment --><dl class="section attention"><dt>Attention</dt><dd>Never call <code>free</code> or <code>delete</code> on a <code><a class="el" href="struct_pylon_1_1_i_pylon_device.html" title="Low Level API: Interface for camera objects. ">Pylon::IPylonDevice</a></code> pointer created by the Transport Layer Factory. Instead, use the <code><a class="el" href="class_pylon_1_1_c_tl_factory.html#ae1f2e7bcf55bf64162f356d4b749f5b6" title="destroys a device ">Pylon::CTlFactory::DestroyDevice()</a></code> method to delete an IPylonDevice pointer.</dd></dl>
<h2><a class="anchor" id="UsingEnumeraionWithFilter"></a>
Applying a Filter when Enumerating Cameras</h2>
<p>For enumerating a range of devices that have certain properties the EnumerateDevices method applying a filter can be used. To define the properties a filter list with device info objects can be passed. A camera is enumerated if it has the properties of at least one device info object in the filter list. The following example enumerates all cameras with the model names in the filter list.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_pylon_includes_8h.html">pylon/PylonIncludes.h</a>&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;ostream&gt;</span></div>
<div class="line"><span class="keyword">using namespace </span>Pylon;</div>
<div class="line"><span class="keyword">using namespace </span>std;</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main()</div>
<div class="line">{</div>
<div class="line">  <a class="code" href="class_pylon_1_1_pylon_auto_init_term.html">PylonAutoInitTerm</a> autoInitTerm;</div>
<div class="line"></div>
<div class="line">  <a class="code" href="class_pylon_1_1_c_tl_factory.html">CTlFactory</a>&amp; TlFactory = <a class="code" href="class_pylon_1_1_c_tl_factory.html#a1d3fbd0bb73b4acd88de7cff893554ab">CTlFactory::GetInstance</a>();</div>
<div class="line"></div>
<div class="line">  <a class="code" href="class_pylon_1_1_device_info_list.html">DeviceInfoList_t</a> filter;</div>
<div class="line">  filter.push_back( <a class="code" href="class_pylon_1_1_c_device_info.html">CDeviceInfo</a>().SetModelName( <span class="stringliteral">&quot;SCA750-60FC&quot;</span>));</div>
<div class="line">  filter.push_back( <a class="code" href="class_pylon_1_1_c_device_info.html">CDeviceInfo</a>().SetModelName( <span class="stringliteral">&quot;SCA780-54FC&quot;</span>));</div>
<div class="line"></div>
<div class="line">  <a class="code" href="class_pylon_1_1_device_info_list.html">DeviceInfoList_t</a> lstDevices;</div>
<div class="line">  TlFactory.<a class="code" href="class_pylon_1_1_c_tl_factory.html#a9a66b37caea9bbd0a50cf377ba4ed94a">EnumerateDevices</a>( lstDevices, filter );</div>
<div class="line">  <span class="keywordflow">if</span> ( ! lstDevices.empty() ) {</div>
<div class="line">    DeviceInfoList_t::const_iterator it;</div>
<div class="line">    <span class="keywordflow">for</span> ( it = lstDevices.begin(); it != lstDevices.end(); ++it )</div>
<div class="line">      cout &lt;&lt; it-&gt;GetFullName();</div>
<div class="line">  }</div>
<div class="line">  <span class="keywordflow">else</span></div>
<div class="line">    cerr &lt;&lt; <span class="stringliteral">&quot;No devices found!&quot;</span> &lt;&lt; endl;</div>
<div class="line"></div>
<div class="line">  <span class="keywordflow">return</span> 0;</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="CreatingSpecificDevices"></a>
Creating Specific Cameras</h2>
<p>For creating a specific device an info object must be set up with the properties of the desired device. In the following example the serial number and the device class are used for identifying the camera. Specifying the device class limits the search to the correct transport layer. This saves computation time when using the transport layer factory.</p>
<div class="fragment"><div class="line">CTlFactory&amp; TlFactory = CTlFactory::GetInstance();</div>
<div class="line"></div>
<div class="line">CDeviceInfo di;</div>
<div class="line">di.SetSerialNumber( <span class="stringliteral">&quot;20399956&quot;</span>);</div>
<div class="line">di.SetDeviceClass( <a class="code" href="group___pylon___transport_layer.html#ga040ff4ac8b3ab081eeb6516a82b21ddc">Basler1394DeviceClass</a>);</div>
<div class="line">IPylonDevice* device = TlFactory.CreateDevice( di);</div>
</div><!-- fragment --><p>The above example can also be written in one line:</p>
<div class="fragment"><div class="line">IPylonDevice* device = CTlFactory::GetInstance().CreateDevice( CDeviceInfo().SetDeviceClass( <a class="code" href="group___pylon___transport_layer.html#ga040ff4ac8b3ab081eeb6516a82b21ddc">Basler1394DeviceClass</a>).SetSerialNumber( <span class="stringliteral">&quot;20399956&quot;</span>));</div>
</div><!-- fragment --><p>The CreateDevice method will fail when multiple devices match the provided properties. If it is required to create any one of multiple devices the CreateFirstDevice method can be used.</p>
<p>The following sample illustrates how to create a device object for a GigE camera with a specific IP address:</p>
<div class="fragment"><div class="line"><span class="preprocessor">    #include &lt;<a class="code" href="_pylon_includes_8h.html">pylon/PylonIncludes.h</a>&gt;</span></div>
<div class="line"><span class="preprocessor">    #include &lt;<a class="code" href="_pylon_gig_e_includes_8h.html">pylon/gige/PylonGigEIncludes.h</a>&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="comment">//....</span></div>
<div class="line"></div>
<div class="line">    CTlFactory&amp; TlFactory = CTlFactory::GetInstance();</div>
<div class="line">    CBaslerGigEDeviceInfo di;</div>
<div class="line">    di.SetIpAddress( <span class="stringliteral">&quot;192.168.0.101&quot;</span>);</div>
<div class="line">    IPylonDevice* device = TlFactory.CreateDevice( di);</div>
</div><!-- fragment --><h1><a class="anchor" id="grab_strategies"></a>
Grab Strategies</h1>
<p>The following grab strategies involve the triggering of the camera device. Depending on the cofiguration of the camera device the following trigger modes are supported.</p>
<ul>
<li>An external trigger, e.g. via digital I/O </li>
<li>A software trigger command </li>
<li>An internal trigger (so-called free running mode).</li>
</ul>
<h2><a class="anchor" id="grab_strategy_one_by_one"></a>
One by One Grab Strategy</h2>
<div class="image">
<img src="pylon_buffer_flow_one_by_one.png" alt="pylon_buffer_flow_one_by_one.png"/>
<div class="caption">
The Buffer Flow Using the One by One Grab Strategy</div></div>
<p> When the One by One grab strategy is used images are processed in the order of their acquisition.</p>
<ul>
<li>The Instant Camera grab engine unqueues buffers from the Empty Buffer Queue and queues the empty buffers at the Low Level API stream grabber (1). </li>
<li>The camera device is triggered (2). An image is acquired by the camera device, the image is transfered to the PC and then grabbed into an empty buffer. </li>
<li>The Instant Camera grab engine thread is notified that a filled buffer is available. The filled buffer is retrieved by the grab engine thread (3) and it is put into the Output Queue. </li>
<li>The application thread waiting inside the <a class="el" href="class_pylon_1_1_c_instant_camera.html#a3af3b05b85ea0aeb68eb5fb1b6dba0c8">RetrieveResult() </a> method is notified, it stops waiting for a grab result, and it retrieves the filled buffer (4) as part of a grab result data object. </li>
<li>The grab result data object is held by a grab result smart pointer. After the application has processed the image data the filled buffer is returned to the Empty Buffer Queue (5). This is done by the grab result smart pointer destuctor or when the grab result data object is explicitly released. Returned buffers are used again for grabbing.</li>
</ul>
<h2><a class="anchor" id="grab_strategy_latest_image_only"></a>
Latest Image Only Grab Strategy</h2>
<div class="image">
<img src="pylon_buffer_flow_latest.png" alt="pylon_buffer_flow_latest.png"/>
<div class="caption">
The Buffer Flow Using the Latest Image Only Grab Strategy</div></div>
<p>The Latest Image Only grab strategy differs from the One By One grab strategy by the size of the Output Queue. The size of the output queue is only 1 buffer. If a new buffer has been grabbed and there is already a buffer waiting in the Output Queue then the buffer waiting in the output queue is automatically returned to the Empty Buffer Queue (4.1). The newly filled buffer is then placed into the output queue. This assures that always the latest grabbed image is provided to the application. Images that are automatically returned to the Empty Buffer Queue are called skipped images.</p>
<h2><a class="anchor" id="grab_strategy_latest_images"></a>
Latest Images Strategy</h2>
<div class="image">
<img src="pylon_buffer_flow_latest.png" alt="pylon_buffer_flow_latest.png"/>
<div class="caption">
The Buffer Flow Using the Latest Images Grab Strategy</div></div>
<p>The Latest Images strategy extends the above strategies. It allows the user to adjust the size of Output Queue. If a new buffer has been grabbed and the output queue is full, the first buffer waiting in the output queue is automatically returned to the Empty Buffer Queue (4.1). The newly filled buffer is then placed into the output queue. This ensures that the application is always provided with the latest grabbed images. Images that are automatically returned to the Empty Buffer Queue are called skipped images. When setting the output queue size to 1, this strategy is equivalent to Latest Image Only grab strategy. When setting the output queue size to CInstantCamera::MaxNumBuffer, this strategy is equivalent to One By One grab strategy.</p>
<h2><a class="anchor" id="grab_strategy_upcoming_image"></a>
Upcoming Image Grab Strategy</h2>
<div class="image">
<img src="pylon_buffer_flow_upcoming.png" alt="pylon_buffer_flow_upcoming.png"/>
<div class="caption">
The Buffer Flow Using the Upcoming Image Grab Strategy</div></div>
<p>The Upcoming Image grab strategy can be used to make sure to get an image that has been grabbed after RetrieveResult() has been called.</p>
<ul>
<li>The Low Level API stream grabber does not receive empty buffers until RetrieveResult() is called. When the application calls RetrieveResult() (1), one empty buffer is unqueued from the Empty Buffer Queue and the empty buffer is then passed to the Low Level API stream grabber (2). </li>
<li>The camera device is triggered (3). An image is acquired by the camera device, it is transfered to the PC and grabbed into the empty buffer. </li>
<li>The now filled buffer is then returned as part of a grab result data object held by a grab result smart pointer (4)(1). </li>
<li>After the application has processed the image data the filled buffer is returned to the Empty Buffer Queue (5). This is done by the grab result smart pointer destuctor or when the grab result data object is explicitly released. If the RetrieveResult() timeout times out the empty buffer is returned to the Empty Buffer Queue.</li>
</ul>
<dl class="section note"><dt>Note</dt><dd>The grab strategy Upcoming Image cannot be used together with USB camera devices. See section <a class="el" href="pylon_advanced_topics.html#usb_changes_transport">Differences in Image Transport</a> and the following section for more information.</dd></dl>
<h1><a class="anchor" id="hi_pnp_ref"></a>
Getting Informed About Camera Device Removal</h1>
<p>To get informed about camera device removal the <a class="el" href="class_pylon_1_1_c_instant_camera.html#a3bc410c61618d7565455751991ce2791"><code>IsCameraDeviceRemoved()</code> </a> method can be queried or a <a class="el" href="pylon_programmingguide.html#hi_eventhandler_configurations">configuration event handler</a> can be registered. The virtual <a class="el" href="class_pylon_1_1_c_configuration_event_handler.html#afe121efea7306bb5f3d0b8a958d82677"><code>OnCameraDeviceRemoved()</code> </a> method is called if a camera device is removed. The device removal is only detected while the Instant Camera and therefore the attached pylon Device are open. The attached pylon Device needs to be destroyed after a device removal. This can be done using the <a class="el" href="class_pylon_1_1_c_instant_camera.html#a5d30e0748815f30d3ef4836facb8795a"><code>DestroyDevice()</code> </a> method.</p>
<p>The following is an example of a configuration event handler that is handling camera device removal:</p>
<div class="fragment"><div class="line"><span class="comment">//Example of a configuration event handler that handles device removal events.</span></div>
<div class="line"><span class="keyword">class </span>CSampleConfigurationEventHandler : <span class="keyword">public</span> <a class="code" href="class_pylon_1_1_c_configuration_event_handler.html">Pylon::CConfigurationEventHandler</a></div>
<div class="line">{</div>
<div class="line"><span class="keyword">public</span>:</div>
<div class="line">    <span class="comment">// This method is called from a different thread when the camera device removal has been detected.</span></div>
<div class="line">    <span class="keywordtype">void</span> <a class="code" href="class_pylon_1_1_c_configuration_event_handler.html#afe121efea7306bb5f3d0b8a958d82677">OnCameraDeviceRemoved</a>( CInstantCamera&amp; <span class="comment">/*camera*/</span>)</div>
<div class="line">    {</div>
<div class="line">        cout &lt;&lt; <span class="stringliteral">&quot;CSampleConfigurationEventHandler::OnCameraDeviceRemoved called.&quot;</span> &lt;&lt; std::endl;</div>
<div class="line">    }</div>
<div class="line">};</div>
</div><!-- fragment --><p>The following example shows how a device removal is detected while the camera is accessed in a loop. The <a class="el" href="class_pylon_1_1_c_instant_camera.html#a3bc410c61618d7565455751991ce2791"><code>IsCameraDeviceRemoved()</code> </a> method can be used to check whether the removal of the camera device has caused an exception while accessing the camera device, e.g. for grabbing.</p>
<div class="fragment"><div class="line"><span class="comment">// Declare a local counter used for waiting.</span></div>
<div class="line"><span class="keywordtype">int</span> loopCount = 0;</div>
<div class="line"></div>
<div class="line"><span class="comment">// Get the transport layer factory.</span></div>
<div class="line">CTlFactory&amp; tlFactory = CTlFactory::GetInstance();</div>
<div class="line"></div>
<div class="line"><span class="comment">// Create an instant camera object with the camera device found first.</span></div>
<div class="line">CInstantCamera camera( tlFactory.CreateFirstDevice());</div>
<div class="line"></div>
<div class="line"><span class="comment">// Print the camera information.</span></div>
<div class="line">cout &lt;&lt; <span class="stringliteral">&quot;Using device &quot;</span> &lt;&lt; camera.GetDeviceInfo().GetModelName() &lt;&lt; endl;</div>
<div class="line">cout &lt;&lt; <span class="stringliteral">&quot;Friendly Name: &quot;</span> &lt;&lt; camera.GetDeviceInfo().GetFriendlyName() &lt;&lt; endl;</div>
<div class="line">cout &lt;&lt; <span class="stringliteral">&quot;Full Name    : &quot;</span> &lt;&lt; camera.GetDeviceInfo().GetFullName() &lt;&lt; endl;</div>
<div class="line">cout &lt;&lt; <span class="stringliteral">&quot;SerialNumber : &quot;</span> &lt;&lt; camera.GetDeviceInfo().GetSerialNumber() &lt;&lt; endl;</div>
<div class="line">cout &lt;&lt; endl;</div>
<div class="line"></div>
<div class="line"><span class="comment">// For demonstration purposes only, register another configuration event handler that handles device removal.</span></div>
<div class="line">camera.RegisterConfiguration( <span class="keyword">new</span> CSampleConfigurationEventHandler, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga6ad39f74e5f882a64461ad02c70567eda06f0a0d28b2552f5b7240e2344d37302">RegistrationMode_Append</a>, <a class="code" href="group___pylon___instant_camera_api_generic.html#ggae495d43181dadd7d44dc47ae1542fed5a33cc17aa219c33ea966e987b906cd364">Cleanup_Delete</a>);</div>
<div class="line"></div>
<div class="line"><span class="comment">// For demonstration purposes only, add a sample configuration event handler to print out information</span></div>
<div class="line"><span class="comment">// about camera use.</span></div>
<div class="line">camera.RegisterConfiguration( <span class="keyword">new</span> CConfigurationEventPrinter, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga6ad39f74e5f882a64461ad02c70567eda06f0a0d28b2552f5b7240e2344d37302">RegistrationMode_Append</a>, <a class="code" href="group___pylon___instant_camera_api_generic.html#ggae495d43181dadd7d44dc47ae1542fed5a33cc17aa219c33ea966e987b906cd364">Cleanup_Delete</a>);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Open the camera. Camera device removal is only detected while the camera is open.</span></div>
<div class="line">camera.Open();</div>
<div class="line"></div>
<div class="line"><span class="comment">// Now, try to detect that the camera has been removed:</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// Ask the user to disconnect a device</span></div>
<div class="line">loopCount = c_loopCounterInitialValue;</div>
<div class="line">cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">&quot;Please disconnect the device (timeout &quot;</span> &lt;&lt; loopCount / 4 &lt;&lt; <span class="stringliteral">&quot;s) &quot;</span> &lt;&lt; endl;</div>
<div class="line"></div>
<div class="line"><span class="keywordflow">try</span></div>
<div class="line">{</div>
<div class="line">    <span class="comment">// Get a camera parameter using generic parameter access.</span></div>
<div class="line">    <a class="code" href="class_gen_api_1_1_c_pointer.html">GenApi::CIntegerPtr</a> width(camera.GetNodeMap().GetNode(<span class="stringliteral">&quot;Width&quot;</span>));</div>
<div class="line"></div>
<div class="line">    <span class="comment">// The following loop accesses the camera. It could also be a loop that is</span></div>
<div class="line">    <span class="comment">// grabbing images. The device removal is handled in the exception handler.</span></div>
<div class="line">    <span class="keywordflow">while</span> ( loopCount &gt; 0)</div>
<div class="line">    {</div>
<div class="line">        <span class="comment">// Print a &quot;.&quot; every few seconds to tell the user we&#39;re waiting for the callback.</span></div>
<div class="line">        <span class="keywordflow">if</span> (--loopCount % 4 == 0)</div>
<div class="line">        {</div>
<div class="line">            cout &lt;&lt; <span class="stringliteral">&quot;.&quot;</span>;</div>
<div class="line">            cout.flush();</div>
<div class="line">        }</div>
<div class="line">        WaitObject::Sleep(250);</div>
<div class="line"></div>
<div class="line">        <span class="comment">// Change the width value in the camera depending on the loop counter.</span></div>
<div class="line">        <span class="comment">// Any access to the camera like setting parameters or grabbing images</span></div>
<div class="line">        <span class="comment">// will fail throwing an exception if the camera has been disconnected.</span></div>
<div class="line">        width-&gt;SetValue( width-&gt;GetMax() - (width-&gt;GetInc() * (loopCount % 2)));</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">}</div>
<div class="line"><span class="keywordflow">catch</span> (<a class="code" href="class_gen_i_cam_1_1_generic_exception.html">GenICam::GenericException</a> &amp;e)</div>
<div class="line">{</div>
<div class="line">    <span class="keywordflow">if</span> ( camera.IsCameraDeviceRemoved())</div>
<div class="line">    {</div>
<div class="line">        <span class="comment">// The camera device has been removed. This caused the exception.</span></div>
<div class="line">        cout &lt;&lt; endl;</div>
<div class="line">        cout &lt;&lt; <span class="stringliteral">&quot;The camera has been removed from the PC.&quot;</span> &lt;&lt; endl;</div>
<div class="line">        cout &lt;&lt; <span class="stringliteral">&quot;The camera device removal triggered an exception:&quot;</span> &lt;&lt; endl</div>
<div class="line">            &lt;&lt; e.<a class="code" href="class_gen_i_cam_1_1_generic_exception.html#ac3f2a44c30188d223fac295bd63a9c72">GetDescription</a>() &lt;&lt; endl;</div>
<div class="line">    }</div>
<div class="line">    <span class="keywordflow">else</span></div>
<div class="line">    {</div>
<div class="line">        <span class="comment">// An unexpected error has occurred.</span></div>
<div class="line">        <span class="comment">// In this example it is handled by exiting the program.</span></div>
<div class="line">        <span class="keywordflow">throw</span>;</div>
<div class="line">    }</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"><span class="keywordflow">if</span> ( !camera.IsCameraDeviceRemoved())</div>
<div class="line">    cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">&quot;Timeout expired&quot;</span> &lt;&lt; endl;</div>
<div class="line"></div>
<div class="line"><span class="comment">// Destroy the Pylon Device representing the detached camera device.</span></div>
<div class="line"><span class="comment">// It cannot be used anymore.</span></div>
<div class="line">camera.DestroyDevice();</div>
</div><!-- fragment --><p>The above code snippets can be found in the code of the <a class="el" href="sample_code.html#sample_DeviceRemovalHandling">DeviceRemovalHandling</a> sample.</p>
<dl class="section note"><dt>Note</dt><dd>The <code>OnCameraDeviceRemoved</code> call is made from a separate thread.</dd></dl>
<h1><a class="anchor" id="hi_parsingchunks_ref"></a>
Accessing Chunk Features</h1>
<p>Basler Cameras can send additional information appended to the image data, such as frame counters, time stamps, and CRC checksums. Data chunks are automatically parsed by the Instant Camera class if activated. The following example shows how to do this using a Device Specific Instant Camera class.</p>
<div class="fragment"><div class="line">        <span class="comment">// Enable chunks in general.</span></div>
<div class="line">        <span class="keywordflow">if</span> (<a class="code" href="group___gen_api___public_interface.html#ga26ed84e6fb3d3d0136c6cace6ddc0cf9">GenApi::IsWritable</a>(camera.ChunkModeActive))</div>
<div class="line">        {</div>
<div class="line">            camera.ChunkModeActive.SetValue(<span class="keyword">true</span>);</div>
<div class="line">        }</div>
<div class="line">        <span class="keywordflow">else</span></div>
<div class="line">        {</div>
<div class="line">            <span class="keywordflow">throw</span> <a class="code" href="group___base___public_impl.html#ga16e6d812cf9af13e0f4106c77689e46b">RUNTIME_EXCEPTION</a>( <span class="stringliteral">&quot;The camera doesn&#39;t support chunk features&quot;</span>);</div>
<div class="line">        }</div>
<div class="line"></div>
<div class="line">        <span class="comment">// Enable time stamp chunks.</span></div>
<div class="line">        camera.ChunkSelector.SetValue(<a class="code" href="namespace_basler___gig_e_camera.html#adb4045e6559563f047d3dcae52b2c485a01d63670adb21d18b84ebf78351d3312">ChunkSelector_Timestamp</a>);</div>
<div class="line">        camera.ChunkEnable.SetValue(<span class="keyword">true</span>);</div>
<div class="line"></div>
<div class="line"><span class="preprocessor">#ifndef USE_USB // USB camera devices provide generic counters. An explicit FrameCounter value is not provided by USB camera devices.</span></div>
<div class="line"><span class="preprocessor"></span>        <span class="comment">// Enable frame counter chunks.</span></div>
<div class="line">        camera.ChunkSelector.SetValue(<a class="code" href="namespace_basler___gig_e_camera.html#adb4045e6559563f047d3dcae52b2c485a06ce57cbf08d3034ed21c9c331f707b4">ChunkSelector_Framecounter</a>);</div>
<div class="line">        camera.ChunkEnable.SetValue(<span class="keyword">true</span>);</div>
<div class="line"><span class="preprocessor">#endif</span></div>
<div class="line"><span class="preprocessor"></span></div>
<div class="line">        <span class="comment">// Enable CRC checksum chunks.</span></div>
<div class="line">        camera.ChunkSelector.SetValue(<a class="code" href="namespace_basler___gig_e_camera.html#adb4045e6559563f047d3dcae52b2c485a484fff12106ff9dcb0e921e87509e595">ChunkSelector_PayloadCRC16</a>);</div>
<div class="line">        camera.ChunkEnable.SetValue(<span class="keyword">true</span>);</div>
</div><!-- fragment --><p>The chunk data can be accessed via parameter members of the device specific grab result data class or using the provided chunk data node map (not shown).</p>
<div class="fragment"><div class="line">        <span class="comment">// Camera.StopGrabbing() is called automatically by the RetrieveResult() method</span></div>
<div class="line">        <span class="comment">// when c_countOfImagesToGrab images have been retrieved.</span></div>
<div class="line">        <span class="keywordflow">while</span>( camera.IsGrabbing())</div>
<div class="line">        {</div>
<div class="line">            <span class="comment">// Wait for an image and then retrieve it. A timeout of 5000 ms is used.</span></div>
<div class="line">            <span class="comment">// RetrieveResult calls the image event handler&#39;s OnImageGrabbed method.</span></div>
<div class="line">            camera.RetrieveResult( 5000, ptrGrabResult, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga038e4dd8fbd49dd4e7ec17cc605d1344af73671a5f5093f8159a973c0ef016a78">TimeoutHandling_ThrowException</a>);</div>
<div class="line"></div>
<div class="line"><span class="preprocessor">#ifdef PYLON_WIN_BUILD</span></div>
<div class="line"><span class="preprocessor"></span>            <span class="comment">// Display the image</span></div>
<div class="line">            Pylon::DisplayImage(1, ptrGrabResult);</div>
<div class="line"><span class="preprocessor">#endif</span></div>
<div class="line"><span class="preprocessor"></span></div>
<div class="line">            cout &lt;&lt; <span class="stringliteral">&quot;GrabSucceeded: &quot;</span> &lt;&lt; ptrGrabResult-&gt;GrabSucceeded() &lt;&lt; endl;</div>
<div class="line"></div>
<div class="line">            <span class="comment">// The result data is automatically filled with received chunk data.</span></div>
<div class="line">            <span class="comment">// (Note:  This is not the case when using the low-level API)</span></div>
<div class="line">            cout &lt;&lt; <span class="stringliteral">&quot;SizeX: &quot;</span> &lt;&lt; ptrGrabResult-&gt;GetWidth() &lt;&lt; endl;</div>
<div class="line">            cout &lt;&lt; <span class="stringliteral">&quot;SizeY: &quot;</span> &lt;&lt; ptrGrabResult-&gt;GetHeight() &lt;&lt; endl;</div>
<div class="line">            <span class="keyword">const</span> uint8_t *pImageBuffer = (uint8_t *) ptrGrabResult-&gt;GetBuffer();</div>
<div class="line">            cout &lt;&lt; <span class="stringliteral">&quot;Gray value of first pixel: &quot;</span> &lt;&lt; (uint32_t) pImageBuffer[0] &lt;&lt; endl;</div>
<div class="line"></div>
<div class="line">            <span class="comment">// Check to see if a buffer containing chunk data has been received.</span></div>
<div class="line">            <span class="keywordflow">if</span> (<a class="code" href="group___pylon___instant_camera_api_generic.html#ggaf50b993da3a56a8a843e4d54e15b2329a5424a047d0e7ac6d548ced0dcad05b3e">PayloadType_ChunkData</a> != ptrGrabResult-&gt;GetPayloadType())</div>
<div class="line">            {</div>
<div class="line">                <span class="keywordflow">throw</span> <a class="code" href="group___base___public_impl.html#ga16e6d812cf9af13e0f4106c77689e46b">RUNTIME_EXCEPTION</a>( <span class="stringliteral">&quot;Unexpected payload type received.&quot;</span>);</div>
<div class="line">            }</div>
<div class="line"></div>
<div class="line">            <span class="comment">// Since we have activated the CRC Checksum feature, we can check</span></div>
<div class="line">            <span class="comment">// the integrity of the buffer first.</span></div>
<div class="line">            <span class="comment">// Note: Enabling the CRC Checksum feature is not a prerequisite for using</span></div>
<div class="line">            <span class="comment">// chunks. Chunks can also be handled when the CRC Checksum feature is deactivated.</span></div>
<div class="line">            <span class="keywordflow">if</span> (ptrGrabResult-&gt;HasCRC() &amp;&amp; ptrGrabResult-&gt;CheckCRC() == <span class="keyword">false</span>)</div>
<div class="line">            {</div>
<div class="line">                <span class="keywordflow">throw</span> <a class="code" href="group___base___public_impl.html#ga16e6d812cf9af13e0f4106c77689e46b">RUNTIME_EXCEPTION</a>( <span class="stringliteral">&quot;Image was damaged!&quot;</span>);</div>
<div class="line">            }</div>
<div class="line"></div>
<div class="line">            <span class="comment">// Access the chunk data attached to the result.</span></div>
<div class="line">            <span class="comment">// Before accessing the chunk data, you should check to see</span></div>
<div class="line">            <span class="comment">// if the chunk is readable. When it is readable, the buffer</span></div>
<div class="line">            <span class="comment">// contains the requested chunk data.</span></div>
<div class="line">            <span class="keywordflow">if</span> (<a class="code" href="group___gen_api___public_interface.html#ga9429c4373073d861a7daa9309b578dd7">IsReadable</a>(ptrGrabResult-&gt;ChunkTimestamp))</div>
<div class="line">                cout &lt;&lt; <span class="stringliteral">&quot;TimeStamp (Result): &quot;</span> &lt;&lt; ptrGrabResult-&gt;ChunkTimestamp.GetValue() &lt;&lt; endl;</div>
<div class="line"></div>
<div class="line"><span class="preprocessor">#ifndef USE_USB // USB camera devices provide generic counters. An explicit FrameCounter value is not provided by USB camera devices.</span></div>
<div class="line"><span class="preprocessor"></span>            <span class="keywordflow">if</span> (<a class="code" href="group___gen_api___public_interface.html#ga9429c4373073d861a7daa9309b578dd7">IsReadable</a>(ptrGrabResult-&gt;ChunkFramecounter))</div>
<div class="line">                cout &lt;&lt; <span class="stringliteral">&quot;FrameCounter (Result): &quot;</span> &lt;&lt; ptrGrabResult-&gt;ChunkFramecounter.GetValue() &lt;&lt; endl;</div>
<div class="line"><span class="preprocessor">#endif</span></div>
<div class="line"><span class="preprocessor"></span></div>
<div class="line">            cout &lt;&lt; endl;</div>
<div class="line">        }</div>
</div><!-- fragment --><p>The above code snippets can be found in the code of the <a class="el" href="sample_code.html#sample_Grab_ChunkImage">Grab_ChunkImage</a> sample.</p>
<h1><a class="anchor" id="hi_grabbingevents_ref"></a>
Handling Camera Events</h1>
<p>Basler GigE Vision, USB 3 Vision and 1394 cameras can send event messages. For example, when a sensor exposure has finished, the camera can send an Exposure End event to the PC. The event can be received by the PC before the image data for the finished exposure has been completely transferred. This is e.g. useful for avoiding unnecessary delay by moving an imaged object further only before the related image data transfer is complete.</p>
<p>The event messages are automatically retrieved and processed by the InstantCamera classes. The information carried by event messages is exposed as nodes in the camera node map and can be accessed like "normal" camera parameters. These nodes are updated when a camera event is received. You can register camera event handler objects that are triggered when event data has been received.</p>
<p>The following camera event handler is used in the camera event example below, which prints the event data on the screen.</p>
<div class="fragment"><div class="line"><span class="comment">// Example handler for camera events.</span></div>
<div class="line"><span class="keyword">class </span>CSampleCameraEventHandler : <span class="keyword">public</span> CameraEventHandler_t</div>
<div class="line">{</div>
<div class="line"><span class="keyword">public</span>:</div>
<div class="line">    <span class="comment">// Only very short processing tasks should be performed by this method. Otherwise, the event notification will block the</span></div>
<div class="line">    <span class="comment">// processing of images.</span></div>
<div class="line">    <span class="keyword">virtual</span> <span class="keywordtype">void</span> OnCameraEvent( Camera_t&amp; camera, intptr_t userProvidedId, <a class="code" href="struct_gen_api_1_1_i_node.html">GenApi::INode</a>* <span class="comment">/* pNode */</span>)</div>
<div class="line">    {</div>
<div class="line">        std::cout &lt;&lt; std::endl;</div>
<div class="line">        <span class="keywordflow">switch</span> ( userProvidedId )</div>
<div class="line">        {</div>
<div class="line">        <span class="keywordflow">case</span> eMyExposureEndEvent: <span class="comment">// Exposure End event</span></div>
<div class="line">            cout &lt;&lt; <span class="stringliteral">&quot;Exposure End event. FrameID: &quot;</span> &lt;&lt; camera.ExposureEndEventFrameID.GetValue() &lt;&lt; <span class="stringliteral">&quot; Timestamp: &quot;</span> &lt;&lt; camera.ExposureEndEventTimestamp.GetValue() &lt;&lt; std::endl &lt;&lt; std::endl;</div>
<div class="line">            <span class="keywordflow">break</span>;</div>
<div class="line">        <span class="keywordflow">case</span> eMyEventOverrunEvent:  <span class="comment">// Event Overrun event</span></div>
<div class="line">            cout &lt;&lt; <span class="stringliteral">&quot;Event Overrun event. FrameID: &quot;</span> &lt;&lt; camera.EventOverrunEventFrameID.GetValue() &lt;&lt; <span class="stringliteral">&quot; Timestamp: &quot;</span> &lt;&lt; camera.EventOverrunEventTimestamp.GetValue() &lt;&lt; std::endl &lt;&lt; std::endl;</div>
<div class="line">            <span class="keywordflow">break</span>;</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line">};</div>
</div><!-- fragment --><p>Handling camera events is disabled by default and needs to be activated first:</p>
<div class="fragment"><div class="line"><span class="comment">// Camera event processing must be activated first, the default is off.</span></div>
<div class="line">camera.GrabCameraEvents = <span class="keyword">true</span>;</div>
</div><!-- fragment --><p>To register a camera event handler the name of the event data node updated on a camera event and a user provided ID need to be passed. The user provided ID can be used to distinguish different events handled by the same event handler.</p>
<div class="fragment"><div class="line"><span class="comment">//Enumeration used for distinguishing different events.</span></div>
<div class="line"><span class="keyword">enum</span> MyEvents</div>
<div class="line">{</div>
<div class="line">    eMyExposureEndEvent  = 100,</div>
<div class="line">    eMyEventOverrunEvent = 200</div>
<div class="line">};</div>
<div class="line"></div>
<div class="line">...</div>
<div class="line"></div>
<div class="line"></div>
<div class="line"><span class="comment">// Register an event handler for the Exposure End event. For each event type, there is a &quot;data&quot; node</span></div>
<div class="line"><span class="comment">// representing the event. The actual data that is carried by the event is held by child nodes of the</span></div>
<div class="line"><span class="comment">// data node. In the case of the Exposure End event, the child nodes are ExposureEndEventFrameID, ExposureEndEventTimestamp,</span></div>
<div class="line"><span class="comment">// and ExposureEndEventStreamChannelIndex. The CSampleCameraEventHandler demonstrates how to access the child nodes within</span></div>
<div class="line"><span class="comment">// a callback that is fired for the parent data node.</span></div>
<div class="line">camera.RegisterCameraEventHandler( pHandler1, <span class="stringliteral">&quot;ExposureEndEventData&quot;</span>, eMyExposureEndEvent, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga6ad39f74e5f882a64461ad02c70567eda622d43aab16f129b874526cd63d1a74b">RegistrationMode_ReplaceAll</a>, <a class="code" href="group___pylon___instant_camera_api_generic.html#ggae495d43181dadd7d44dc47ae1542fed5ab2a4bc04535c971546bf9ad9511e80dc">Cleanup_None</a>);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Register the same handler for a second event. The user-provided ID can be used</span></div>
<div class="line"><span class="comment">// to distinguish between the events.</span></div>
<div class="line">camera.RegisterCameraEventHandler( pHandler1, <span class="stringliteral">&quot;EventOverrunEventData&quot;</span>, eMyEventOverrunEvent, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga6ad39f74e5f882a64461ad02c70567eda06f0a0d28b2552f5b7240e2344d37302">RegistrationMode_Append</a>, <a class="code" href="group___pylon___instant_camera_api_generic.html#ggae495d43181dadd7d44dc47ae1542fed5ab2a4bc04535c971546bf9ad9511e80dc">Cleanup_None</a>);</div>
</div><!-- fragment --><p>The event of interest must be enabled in the camera. Events are then handled in the <a class="el" href="class_pylon_1_1_c_instant_camera.html#a3af3b05b85ea0aeb68eb5fb1b6dba0c8"><code>RetrieveResult()</code> </a> call while waiting for images.</p>
<div class="fragment"><div class="line"><span class="comment">// Enable sending of Exposure End events.</span></div>
<div class="line"><span class="comment">// Select the event to receive.</span></div>
<div class="line">camera.EventSelector.SetValue(<a class="code" href="namespace_basler___gig_e_camera.html#ac351d04ad16f30c21cde8b2dc67e1a95aff6d3643784d09a19679ac942fb76484">EventSelector_ExposureEnd</a>);</div>
<div class="line"><span class="comment">// Enable it.</span></div>
<div class="line">camera.EventNotification.SetValue(<a class="code" href="namespace_basler___gig_e_camera.html#ae5088f3810ce630e1ed34e5b8fe5bafea6d5293db5f74c6ec5129d292eb4a8c2f">EventNotification_GenICamEvent</a>);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Enable sending of Event Overrun events.</span></div>
<div class="line">camera.EventSelector.SetValue(<a class="code" href="namespace_basler___gig_e_camera.html#ac351d04ad16f30c21cde8b2dc67e1a95ad155b6506f1279d8b7830332c73dde6a">EventSelector_EventOverrun</a>);</div>
<div class="line">camera.EventNotification.SetValue(<a class="code" href="namespace_basler___gig_e_camera.html#ae5088f3810ce630e1ed34e5b8fe5bafea6d5293db5f74c6ec5129d292eb4a8c2f">EventNotification_GenICamEvent</a>);</div>
<div class="line"></div>
<div class="line"></div>
<div class="line"><span class="comment">// Start the grabbing of c_countOfImagesToGrab images.</span></div>
<div class="line">camera.StartGrabbing( c_countOfImagesToGrab);</div>
<div class="line"></div>
<div class="line"><span class="comment">// This smart pointer will receive the grab result data.</span></div>
<div class="line">CGrabResultPtr ptrGrabResult;</div>
<div class="line"></div>
<div class="line"><span class="comment">// Camera.StopGrabbing() is called automatically by the RetrieveResult() method</span></div>
<div class="line"><span class="comment">// when c_countOfImagesToGrab images have been retrieved.</span></div>
<div class="line"><span class="keywordflow">while</span> ( camera.IsGrabbing())</div>
<div class="line">{</div>
<div class="line">    <span class="comment">// Execute the software trigger. Wait up to 1000 ms for the camera to be ready for trigger.</span></div>
<div class="line">    <span class="keywordflow">if</span> ( camera.WaitForFrameTriggerReady( 1000, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga038e4dd8fbd49dd4e7ec17cc605d1344af73671a5f5093f8159a973c0ef016a78">TimeoutHandling_ThrowException</a>))</div>
<div class="line">    {</div>
<div class="line">        camera.ExecuteSoftwareTrigger();</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Retrieve grab results and notify the camera event and image event handlers.</span></div>
<div class="line">    camera.RetrieveResult( 5000, ptrGrabResult, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga038e4dd8fbd49dd4e7ec17cc605d1344af73671a5f5093f8159a973c0ef016a78">TimeoutHandling_ThrowException</a>);</div>
<div class="line">    <span class="comment">// Nothing to do here with the grab result, the grab results are handled by the registered event handler.</span></div>
<div class="line">}</div>
</div><!-- fragment --><p>The above code snippets can be found in the code of the <a class="el" href="sample_code.html#sample_Grab_CameraEvents">Grab_CameraEvents</a> sample.</p>
<h1><a class="anchor" id="GettingInformedAboutParameterChanges"></a>
Getting Informed About Parameter Changes</h1>
<p>The GenICam API provides the functionality for installing callback functions that will be called when a parameter's value or state (e.g. the access mode or value range) have been changed. It is possible to either install a C function or a C++ class member function as a callback.</p>
<p>Each callback is installed for a specific parameter. If the parameter itself has been touched or if another parameter that can influence the state of the parameter has been changed, the callback will be fired.</p>
<p>The following example demonstrates how to install callbacks for the <code>Width</code> parameter: </p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_pylon_includes_8h.html">pylon/PylonIncludes.h</a>&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;pylon/gige/BaslerGigEInstantcamera.h&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;ostream&gt;</span></div>
<div class="line"><span class="keyword">using namespace </span>Pylon;</div>
<div class="line"><span class="keyword">using namespace </span>std;</div>
<div class="line"></div>
<div class="line"><span class="comment">// C callback function</span></div>
<div class="line"><span class="keywordtype">void</span> staticcallback(<a class="code" href="struct_gen_api_1_1_i_node.html">GenApi::INode</a>* pNode )</div>
<div class="line">{</div>
<div class="line">  cout &lt;&lt; <span class="stringliteral">&quot;Perhaps the value or state of &quot;</span> &lt;&lt; pNode-&gt;<a class="code" href="struct_gen_api_1_1_i_node.html#a4840e3c5b4800d8ca5d629e73c96d204">GetName</a>() &lt;&lt; <span class="stringliteral">&quot;has changed.&quot;</span> &lt;&lt; endl;</div>
<div class="line">  <span class="keywordflow">if</span> ( <a class="code" href="group___gen_api___public_interface.html#ga9429c4373073d861a7daa9309b578dd7">GenApi::IsReadable</a>( pNode ) ) {</div>
<div class="line">    <a class="code" href="class_gen_api_1_1_c_pointer.html">GenApi::CValuePtr</a> ptrValue( pNode );</div>
<div class="line">    cout &lt;&lt; <span class="stringliteral">&quot;The current value is &quot;</span> &lt;&lt; ptrValue-&gt;ToString() &lt;&lt; endl;</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"><span class="keyword">class </span>C</div>
<div class="line">{</div>
<div class="line"><span class="keyword">public</span>:</div>
<div class="line">  <span class="comment">// Member function as callback function</span></div>
<div class="line">  <span class="keywordtype">void</span> membercallback(<a class="code" href="struct_gen_api_1_1_i_node.html">GenApi::INode</a>* pNode )</div>
<div class="line">  {</div>
<div class="line">    cout &lt;&lt; <span class="stringliteral">&quot;Perhaps the value or state of &quot;</span> &lt;&lt; pNode-&gt;<a class="code" href="struct_gen_api_1_1_i_node.html#a4840e3c5b4800d8ca5d629e73c96d204">GetName</a>() &lt;&lt; <span class="stringliteral">&quot;has changed.&quot;</span> &lt;&lt; endl;</div>
<div class="line">    <span class="keywordflow">if</span> ( <a class="code" href="group___gen_api___public_interface.html#ga9429c4373073d861a7daa9309b578dd7">GenApi::IsReadable</a>( pNode ) ) {</div>
<div class="line">      <a class="code" href="class_gen_api_1_1_c_pointer.html">GenApi::CValuePtr</a> ptrValue( pNode );</div>
<div class="line">      cout &lt;&lt; <span class="stringliteral">&quot;The current value is &quot;</span> &lt;&lt; ptrValue-&gt;ToString() &lt;&lt; endl;</div>
<div class="line">    }</div>
<div class="line">  }</div>
<div class="line">};</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main()</div>
<div class="line">{</div>
<div class="line">  <a class="code" href="class_pylon_1_1_pylon_auto_init_term.html">PylonAutoInitTerm</a> autoInitTerm;</div>
<div class="line"></div>
<div class="line">  C cb;  <span class="comment">// c.membercallback() will be installed as callback</span></div>
<div class="line"></div>
<div class="line">  <span class="comment">// Only look for cameras supported by Camera_t.</span></div>
<div class="line">  <a class="code" href="class_pylon_1_1_c_device_info.html">CDeviceInfo</a> info;</div>
<div class="line">  info.<a class="code" href="class_pylon_1_1_c_device_info.html#a9212c5956d9d7a8c205d0de022e3c633">SetDeviceClass</a>( Camera_t::DeviceClass());</div>
<div class="line"></div>
<div class="line">  <span class="comment">// Create an instant camera object with the first found camera device matching the specified device class.</span></div>
<div class="line">  CBaslerGigEInstantCamera_t Camera( <a class="code" href="class_pylon_1_1_c_tl_factory.html#a1d3fbd0bb73b4acd88de7cff893554ab">CTlFactory::GetInstance</a>().CreateFirstDevice( info));</div>
<div class="line">  Camera.Open();</div>
<div class="line"></div>
<div class="line">  <span class="comment">// Install the C-function as callback</span></div>
<div class="line">  <a class="code" href="namespace_gen_api.html#aa699284b069f02e89d85a0f7525a8777">GenApi::CallbackHandleType</a> h1 =</div>
<div class="line">    <a class="code" href="group___gen_api___public_utilities.html#ga9a5c3e2bce3cdc6db812068660832f1f">GenApi::Register</a>( Camera.Width.GetNode(), &amp;staticcallback );</div>
<div class="line"></div>
<div class="line">  <span class="comment">// Install a member function as callback</span></div>
<div class="line">  <a class="code" href="namespace_gen_api.html#aa699284b069f02e89d85a0f7525a8777">GenApi::CallbackHandleType</a> h2 =</div>
<div class="line">    <a class="code" href="group___gen_api___public_utilities.html#ga9a5c3e2bce3cdc6db812068660832f1f">GenApi::Register</a>( Camera.Width.GetNode(), cb, &amp;C::membercallback );</div>
<div class="line"></div>
<div class="line">  <span class="comment">// This will trigger the callback functions</span></div>
<div class="line">  Camera.Width.SetValue( 128 );</div>
<div class="line"></div>
<div class="line">  <span class="comment">// Uninstall the callback functions</span></div>
<div class="line">  Camera.Width.GetNode()-&gt;DeregisterCallback(h2);</div>
<div class="line">  Camera.Width.GetNode()-&gt;DeregisterCallback(h1);</div>
<div class="line"></div>
<div class="line">  <span class="comment">// Close the camera object</span></div>
<div class="line">  Camera.Close();</div>
<div class="line"></div>
<div class="line">}</div>
</div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>For the nodes of the camera node map a Camera Event Handler can alternatively be used to get informed about parameter changes. This is because a GenApi node call back is registered internally for the node identified by the node's name when a Camera Event handler is registered. This callback triggers a call to the <code>CCameraEventHandler::OnCameraEvent()</code> method. Using a Camera Event Handler can be more convenient. See the <a class="el" href="sample_code.html#sample_Grab_CameraEvents">Grab_CameraEvents</a> sample for more information about how to register a Camera Event Handler.</dd></dl>
<h1><a class="anchor" id="bindingrules"></a>
How to Control the Location of the Camera Description Files Used by pylon</h1>
<p>When a Camera object is created, the <a class="el" href="namespace_gen_api.html" title="Contains definitions of the types of GenICam GenApi modules. ">GenApi</a> node map used to access the camera parameters is generated from a camera description XML file. See the <a class="el" href="pylon_advanced_topics.html#GenApiNodeMaps">GenApi Node Maps</a> section for a description of <a class="el" href="namespace_gen_api.html" title="Contains definitions of the types of GenICam GenApi modules. ">GenApi</a> node maps.</p>
<p>The XML file is downloaded from the camera by default. It is possible to change this default behavior. The location of the XML files is defined by a set of rules. The rules are stored in the /opt/pylon4/share/pylon/ConfigFileRegistry/StandardRules.xml file.</p>
<p>The following example describes a rule that matches certain scout GigE cameras. For the matching cameras, an XML file stored in the PC's filesystem is used instead of downloading the file from the camera.</p>
<div class="fragment"><div class="line">&lt;TransportLayer name=<span class="stringliteral">&quot;BaslerGigE&quot;</span>&gt;</div>
<div class="line">  &lt;Rule priority=<span class="stringliteral">&quot;10&quot;</span>&gt;</div>
<div class="line">    &lt;Manufacturer&gt;Basler&lt;/Manufacturer&gt;</div>
<div class="line">    &lt;Name&gt;sca.*&lt;/Name&gt;</div>
<div class="line">    &lt;SerialNumber&gt;206102.*&lt;/SerialNumber&gt;</div>
<div class="line">    &lt;Download&gt;no&lt;/Download&gt;</div>
<div class="line">    &lt;File&gt;c:\myfiles\myConfigFile.xml&lt;/File&gt;</div>
<div class="line">  &lt;/Rule&gt;</div>
<div class="line">&lt;/TransportLayer&gt;</div>
</div><!-- fragment --><p>The config file registry rule will be applied to cameras created by the BaslerGigE transport layer, i.e., by the transport layer for GigE cameras. The rule applies to all Basler scout cameras (scA....) where the serial number starts with '206102'. For the matching cameras, the specified camera configuration file is to be used instead of downloading it from the camera.</p>
<p>Each rule has a priority. When several rules match a device, the rule with the highest priority number is applied.</p>
<p>For the <code>Manufacturer</code>, <code>Name</code>, and <code>SerialNumber</code> rule criteria, regular expressions in Perl syntax can be specified.</p>
<p>It is possible to specifiy a <code>File</code> even when <code>Download</code> is set to 'yes'. In this case, the specified file will be used if the download from the camera has failed for some reason.</p>
<p>The above-mentioned StandardRules.xml file must not be edited. Instead, create a new rules file in the ConfigFileRegistry folder. The StandardRules.xml file contains a copy and paste template for such a custom rules file. The name of the XML file can be chosen arbitrarily, the file extension must be '.xml'.</p>
<h1><a class="anchor" id="MulticastGrabbing"></a>
Receiving Image Data</h1>
<p>Basler GigE cameras can be configured to send the image data stream to multiple destinations. Either IP multicasts or IP broadcasts can be used.</p>
<h2><a class="anchor" id="TypeOfApplication"></a>
The Controlling Application and the Monitoring Application</h2>
<p>When multiple applications on different PCs expect to receive data streams from the same camera, one application is responsible for configuring the camera and for starting and stopping the data acquisition. This application is called the <b>controlling application</b>. Other applications that also expect to receive the data stream are called <b>monitoring applications</b>. These applications must connect to the camera in read-only mode, and can read all camera parameters but can not change them.</p>
<p>Device enumeration and device creation is identical for the controlling and the monitoring application. Each application type must create a Camera Object for the camera device from which it will recieve data. The multicast device creation is realized in the same way as for unicast setups (see earlier explanation).</p>
<p>Example of the configuration of an Instant Camera to act as monitor:</p>
<div class="fragment"><div class="line">Camera.MonitorModeActive = <span class="keyword">true</span>;</div>
</div><!-- fragment --><p>When using the Low Level API, the parameters passed to the Camera Object's <a class="el" href="class_pylon_1_1_c_pylon_device_proxy_t.html#a645af231e86c1853454ef1684cae10b4">Open() </a> method determine whether an application acts as controlling or as monitoring application. The following code snippet illustrates how a monitoring application must call the <a class="el" href="class_pylon_1_1_c_pylon_device_proxy_t.html#a645af231e86c1853454ef1684cae10b4">Open() </a> method:</p>
<div class="fragment"><div class="line"><span class="comment">// Low Level-API only</span></div>
<div class="line"><span class="comment">// Open the camera in stream mode to receive multicast packets (monitoring mode)</span></div>
<div class="line"><span class="comment">// In this mode the camera must be controlled by another application that must be in controlling mode</span></div>
<div class="line">Camera.Open(<a class="code" href="group___pylon___transport_layer.html#gga8ef525f5ebe32f59483928d77bf96afcadd694606dc3643e5ef2b0cce271d1675">Stream</a>);</div>
</div><!-- fragment --><p>When using the low level API the controlling application can either call the <a class="el" href="class_pylon_1_1_c_pylon_device_proxy_t.html#a645af231e86c1853454ef1684cae10b4">Open() </a> method without passing in any arguments (the default parameters for the <a class="el" href="class_pylon_1_1_c_pylon_device_proxy_t.html#a645af231e86c1853454ef1684cae10b4">Open() </a> method make sure that the device will be opened in control and stream mode), or can specify the access mode for the <a class="el" href="class_pylon_1_1_c_pylon_device_proxy_t.html#a645af231e86c1853454ef1684cae10b4">Open() </a> method explicitly:</p>
<div class="fragment"><div class="line"><span class="comment">// Open the camera in controlling mode but without setting the Exclusive flag for the access mode</span></div>
<div class="line">Camera.Open(<a class="code" href="group___pylon___transport_layer.html#gga8ef525f5ebe32f59483928d77bf96afcadd694606dc3643e5ef2b0cce271d1675">Stream</a> | <a class="code" href="group___pylon___transport_layer.html#gga8ef525f5ebe32f59483928d77bf96afca55c0ae5b52a7cbb9224ebb9f0ca347cb">Control</a>);</div>
</div><!-- fragment --><p>It is important that the controlling application does not set the <a class="el" href="group___pylon___transport_layer.html#ga8ef525f5ebe32f59483928d77bf96afc">Exclusive </a> flag for the access mode. Using the <code>Exclusive</code> flag would prevent monitoring applications from accessing the camera at all. When the controlling application also wants to receive camera events, the <code>Events</code> flag must be added to the access mode parameter.</p>
<p>The controlling application and the monitoring application must create Stream Grabber objects in the same way as is done in unicast setups. Configuring the Stream Grabber for multicasts or broadcasts is explained in the next sections.</p>
<h2><a class="anchor" id="SettingUpControllingApplication"></a>
Setting Up the Controlling Application for Enabling Multicast and Broadcast</h2>
<p>The <a class="el" href="class_basler___gig_e_stream_params_1_1_c_gig_e_stream_params___params.html#a22c61055d3ffbbb4d5411efe51dd82c3">TransmissionType </a> parameter of the GigE Stream Grabber class can be used to configure whether the camera sends the data stream to a single destination or to multiple destinations.</p>
<p>When the camera sends the image data using <b>limited broadcasts</b>, where the camera sends the data to the address 255.255.255.255, the data is sent to all devices in the local network. 'Limited' means, that the data is not sent to destinations behind a router, e.g. to computers in the internet. To enable limited broadcasts, the controlling application must set the <a class="el" href="class_basler___gig_e_stream_params_1_1_c_gig_e_stream_params___params.html#a22c61055d3ffbbb4d5411efe51dd82c3">TransmissionType </a> parameter to <code>TransmissionType_LimitedBroadcast</code>. The camera sends the data to a specific port. See the <a class="el" href="pylon_advanced_topics.html#PortSelection">Selecting a Destination Port</a> section for setting up the destination port.</p>
<p>When the camera sends the image data using <b>subnet directed broadcasts</b>, the camera sends the data to all devices that are in the same subnet as the camera. To enable subnet directed broadcasts, set the <a class="el" href="class_basler___gig_e_stream_params_1_1_c_gig_e_stream_params___params.html#a22c61055d3ffbbb4d5411efe51dd82c3">TransmissionType </a> parameter to <code>TransmissionType_SubnetDirectedBroadcast</code>. See the <a class="el" href="pylon_advanced_topics.html#PortSelection">Selecting a Destination Port</a> section for setting up the destination port that receives the data from the camera.</p>
<p>The disadvantage of using broadcasts is that the camera sends the data to all recipients in a network, regardless of whether or not the devices need the data. The network traffic causes a certain CPU load and consumes network bandwidth even for the devices not needing the streaming data.</p>
<p>When the camera sends the image data using <b>multicasts</b>, the data is only sent to those devices that expect the data stream. A device claims its interest in receiving the data by joining a so-called <b>multicast group</b>. A multicast group is defined by an IP address taken from the multicast address range (224.0.0.0 to 239.255.255.255). A member of a specific multicast group only receives data destined for this group. Data for other groups is not received. Usually, network adapters and network switches are able to filter network packets efficiently on hardware level, preventing a CPU load due to the multicast network traffic for those devices in the network, that are not part of the multicast group.</p>
<p>When multicasting is enabled for pylon, pylon automatically takes care of joining and leaving the multicast groups defined by the destination IP address. Keep in mind that some addresses from the multicast address range are reserved for general purposes. The address range from 239.255.0.0 to 239.255.255.255 is assigned by RFC 2365 as a locally administered address space. Use adresses in this range if you are not sure.</p>
<p>To enable multicast streaming, the controlling application must set the <a class="el" href="class_basler___gig_e_stream_params_1_1_c_gig_e_stream_params___params.html#a22c61055d3ffbbb4d5411efe51dd82c3">TransmissionType </a> parameter to <code>TransmissionType_Multicast</code> and set the <a class="el" href="class_basler___gig_e_stream_params_1_1_c_gig_e_stream_params___params.html#aac54e3c74552dbebf18448fe508660bb">DestinationAddr </a> parameter to a valid multicast IP address. In addition to the address, a port must be specified. See the <a class="el" href="pylon_advanced_topics.html#PortSelection">Selecting a Destination Port</a> section for setting up the destination port that receives the data from the camera.</p>
<p>Example using the Device Specific Instant Camera for GigE:</p>
<div class="fragment"><div class="line">Camera.GetStreamGrabberParams().DestinationAddr = <span class="stringliteral">&quot;239.0.0.1&quot;</span>;</div>
<div class="line">Camera.GetStreamGrabberParams().DestinationPort = 49154;</div>
</div><!-- fragment --><p>Example (Low Level):</p>
<div class="fragment"><div class="line">StreamGrabber.DestinationAddr = <span class="stringliteral">&quot;239.0.0.1&quot;</span>;</div>
<div class="line">StreamGrabber.DestinationPort = 49154;</div>
</div><!-- fragment --><p>On protocol level, multicasting involves a so-called IGMP message (IGMP = Internet Group Management Protocol). To benefit from multicasting, managed network switches should be used. These managed network switches support the IGMP protocol and only forward multicast packets if there is a device connected that has joined the corresponding multicast group. If the switch does not support the IGMP protocol, multicast is equivalent to broadcasting.</p>
<p>When multiple cameras are to multicast in the same network, each camera should stream to a different multicast group. Streaming to different multicast groups reduces the CPU load and saves network bandwidth if the network switches used support the IGMP protocol.</p>
<h2><a class="anchor" id="SettingUpMonitorApplication"></a>
Setting Up the Monitoring Application for Receiving Multicast and Broadcast Streams</h2>
<p>Two cases must be differentiated: </p>
<ul>
<li>The monitoring application opens the Stream Grabber after the controlling application has set up its Stream Grabber for broadcasts or multicasts. </li>
<li>The monitoring application opens the Stream Grabber before the controlling application opens its Stream Grabber.</li>
</ul>
<p>For the first case, setting up a Stream Grabber for a monitoring application is quite easy. Since the controlling application has already configured the camera (i.e. the destination address and the destination port are set by the controlling application), these settings can be easily read from the camera. To let the monitoring application's Stream Grabber read the settings from the camera, the monitoring application must set the Stream Grabber's <a class="el" href="class_basler___gig_e_stream_params_1_1_c_gig_e_stream_params___params.html#a22c61055d3ffbbb4d5411efe51dd82c3">TransmissionType </a> parameter to <code>TransmissionType_UseCameraConfig</code> and then call the Stream Grabber's <code>Open()</code> method.</p>
<p>Example using the Device Specific Instant Camera for GigE:</p>
<div class="fragment"><div class="line"><span class="comment">// Select transmission type. If the camera is already controlled by another application</span></div>
<div class="line"><span class="comment">// and configured for multicast or broadcast, the active camera configuration can be used</span></div>
<div class="line"><span class="comment">// (IP Address and Port will be auto set).</span></div>
<div class="line">Camera.GetStreamGrabberParams().TransmissionType = <a class="code" href="namespace_basler___gig_e_stream_params.html#a72ed4d48478327b7d99507dcc5eb09e7a044d3764df6ddaef13f48a2143eb54c8">TransmissionType_UseCameraConfig</a>;</div>
<div class="line"></div>
<div class="line"><span class="comment">// Start grabbing...</span></div>
</div><!-- fragment --><p>Example (low level):</p>
<div class="fragment"><div class="line"><span class="comment">// Select transmission type. If the camera is already controlled by another application</span></div>
<div class="line"><span class="comment">// and configured for multicast or broadcast, the active camera configuration can be used</span></div>
<div class="line"><span class="comment">// (IP Address and Port will be auto set).</span></div>
<div class="line">StreamGrabber.TransmissionType = <a class="code" href="namespace_basler___gig_e_stream_params.html#a72ed4d48478327b7d99507dcc5eb09e7a044d3764df6ddaef13f48a2143eb54c8">TransmissionType_UseCameraConfig</a>;</div>
<div class="line"></div>
<div class="line"><span class="comment">// Open the stream grabber</span></div>
<div class="line">StreamGrabber.Open();</div>
</div><!-- fragment --><p>For the second case, where the monitoring application opens the Stream Grabber object before the controlling application opens its Stream Grabber, the <code>TransmissionType_UseCameraConfig</code> cannot be used. Instead, the controlling application and all monitoring applications must use the same settings for the following IP destination related parameters:</p>
<ul>
<li><a class="el" href="class_basler___gig_e_stream_params_1_1_c_gig_e_stream_params___params.html#a22c61055d3ffbbb4d5411efe51dd82c3">TransmissionType </a> </li>
<li><a class="el" href="class_basler___gig_e_stream_params_1_1_c_gig_e_stream_params___params.html#aac54e3c74552dbebf18448fe508660bb">DestinationAddr </a> </li>
<li><a class="el" href="class_basler___gig_e_stream_params_1_1_c_gig_e_stream_params___params.html#a1c0f2e27e1420fc53bdeefc64c8ec2c2">DestinationPort </a></li>
</ul>
<p>Note, when using broadcasts, the <a class="el" href="class_basler___gig_e_stream_params_1_1_c_gig_e_stream_params___params.html#aac54e3c74552dbebf18448fe508660bb">DestinationAddr </a> parameter is read-only. <a class="el" href="namespace_pylon.html" title="Contains definitions of pylon types. ">Pylon</a> will configure the camera for using the correct broadcast address.</p>
<p>When the controlling application and the monitoring application set the destination related parameters explicitly, it does not matter which application opens the Stream Grabber first.</p>
<h2><a class="anchor" id="PortSelection"></a>
Selecting a Destination Port</h2>
<p>The destination for the camera's data is specified by the destination IP address and the destination IP port. For multicasts, the monitoring and the controlling application must configure the Stream Grabbers for the same multicast IP address. Correspondingly, for broadcasts, the monitoring and the controlling application must use the same broadcast IP address that is automatically set by pylon.</p>
<p>In both cases, the controlling and the monitoring application must specify the same destination port. All applications must use a port that is not used on all PCs receiving the data stream. The destination port is set by using the Stream Grabber's <a class="el" href="class_basler___gig_e_stream_params_1_1_c_gig_e_stream_params___params.html#a1c0f2e27e1420fc53bdeefc64c8ec2c2">DestinationPort </a> parameter.</p>
<p>When a monitoring application sets the <a class="el" href="class_basler___gig_e_stream_params_1_1_c_gig_e_stream_params___params.html#a22c61055d3ffbbb4d5411efe51dd82c3">TransmissionType </a> parameter to <code>TransmissionType_UseCameraConfig</code>, a monitoring application automatically uses the port that the controlling application has written to the corresponding camera register. In that case, the controlling application must use a port that is not used for the PC where the controlling application is running on and that is not used for all PCs where monitoring applications are running on.</p>
<p>When the <a class="el" href="class_basler___gig_e_stream_params_1_1_c_gig_e_stream_params___params.html#a1c0f2e27e1420fc53bdeefc64c8ec2c2">DestinationPort </a> parameter is set to 0 pylon automatically selects an unused port. This is very convenient for applications using only unicast streaming. In the case of multicast or broadcast, a parameter value of 0 can only be used by the controlling application and only if the monitoring application uses the <code>TransmissionType_UseCameraConfig</code> value for the <a class="el" href="class_basler___gig_e_stream_params_1_1_c_gig_e_stream_params___params.html#a22c61055d3ffbbb4d5411efe51dd82c3">TransmissionType </a> parameter. Since there is no guarantee that the port auomatically chosen by the controlling application is not used on PCs where monitoring applications are running, we do not recommend to use this auto selection mechanism for the port for broadcast or multicast.</p>
<h2><a class="anchor" id="MulticastGrabbing"></a>
Receiving Image Data</h2>
<p>For broadcast or multicast setups grabbing images is realized in the same way as for unicast setups. Controlling and monitoring applications must allocate memory for grabbing, register the buffers at the Stream Grabber, enqueue the buffers and retrieve them back from the Stream Grabber. The only difference between monitoring application and controlling application is that only the controlling application starts and stops the image acquisition in the camera.</p>
<h2><a class="anchor" id="MulticastSample"></a>
Sample Program</h2>
<p>The pylon SDK contains a simple sample program called <a class="el" href="sample_code.html#sample_Grab_MultiCast">Grab_MultiCast</a>. This sample illustrates how to set up a controlling application and a monitoring application for multicast.</p>
<h1><a class="anchor" id="loadsavecamerafeatures"></a>
Saving and Restoring Camera Features to/from Files</h1>
<p>This section describes how to write the current values to file for those camera features that are readable and writable. It is also demonstrated how to write the saved feature values back to the device. Saving and restoring the camera features is performed by using the <a class="el" href="class_pylon_1_1_c_feature_persistence.html" title="Class for saving and restoring a camera features to and from a file. ">Pylon::CFeaturePersistence</a> class.</p>
<h2><a class="anchor" id="readfeatures"></a>
Writing the Camera Features to a File</h2>
<p>Use the static <a class="el" href="class_pylon_1_1_c_feature_persistence.html#aafc8caa4484e6a744954c5e9c633051c" title="Saves the node tree to the file. ">Pylon::CFeaturePersistence::Save()</a> method to save the current camera feature values to a file.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_pylon_utility_includes_8h.html">pylon/PylonUtilityIncludes.h</a>&gt;</span></div>
<div class="line"></div>
<div class="line">  <span class="comment">// ...</span></div>
<div class="line"></div>
<div class="line">  <span class="keyword">const</span> <span class="keywordtype">char</span> Filename[] = <span class="stringliteral">&quot;NodeMap.pfs&quot;</span>; <span class="comment">// Pylon Feature Stream</span></div>
<div class="line"></div>
<div class="line">  <span class="comment">// ...</span></div>
<div class="line"></div>
<div class="line">  <span class="comment">// Open the camera</span></div>
<div class="line">  Camera.Open();</div>
<div class="line"></div>
<div class="line">  <span class="comment">// Save the content of the camera&#39;s node map into the file</span></div>
<div class="line">  <span class="keywordflow">try</span></div>
<div class="line">  {</div>
<div class="line">    CFeaturePersistence::Save( Filename, &amp;Camera.GetNodeMap() );</div>
<div class="line">  }</div>
<div class="line">  <span class="keywordflow">catch</span> (<a class="code" href="class_gen_i_cam_1_1_generic_exception.html">GenICam::GenericException</a> &amp;e)</div>
<div class="line">  {</div>
<div class="line">    <span class="comment">// Error handling</span></div>
<div class="line">    cerr &lt;&lt; <span class="stringliteral">&quot;An exception occurred!&quot;</span> &lt;&lt; endl &lt;&lt; e.<a class="code" href="class_gen_i_cam_1_1_generic_exception.html#ac3f2a44c30188d223fac295bd63a9c72">GetDescription</a>() &lt;&lt; endl;</div>
<div class="line">  }</div>
</div><!-- fragment --><h2><a class="anchor" id="savefeatures"></a>
Writing the Feature Values Back to the Camera</h2>
<p>Use the static method <a class="el" href="class_pylon_1_1_c_feature_persistence.html#ab0113f519bdd95b672daaf249bf21974" title="Loads the features from the file to the node tree. ">Pylon::CFeaturePersistence::Load()</a> to restore the camera values from a file.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_pylon_utility_includes_8h.html">pylon/PylonUtilityIncludes.h</a>&gt;</span></div>
<div class="line">  <span class="comment">// ...</span></div>
<div class="line">  <span class="keyword">const</span> <span class="keywordtype">char</span> Filename[] = <span class="stringliteral">&quot;NodeMap.pfs&quot;</span>;          <span class="comment">// Pylon Feature Stream</span></div>
<div class="line"></div>
<div class="line">  <span class="comment">// ...</span></div>
<div class="line"></div>
<div class="line">  <span class="comment">// Open the camera</span></div>
<div class="line">  Camera.Open();</div>
<div class="line"></div>
<div class="line">  <span class="comment">// Read the content of the file back to the camera&#39;s node map with validation on</span></div>
<div class="line">  <span class="keywordflow">try</span></div>
<div class="line">  {</div>
<div class="line">    CFeaturePersistence::Load( Filename, &amp;Camera.GetNodeMap(), true );</div>
<div class="line">  }</div>
<div class="line">  <span class="keywordflow">catch</span> (<a class="code" href="class_gen_i_cam_1_1_generic_exception.html">GenICam::GenericException</a> &amp;e)</div>
<div class="line">  {</div>
<div class="line">    <span class="comment">// Error handling</span></div>
<div class="line">    cerr &lt;&lt; <span class="stringliteral">&quot;An exception occurred!&quot;</span> &lt;&lt; endl &lt;&lt; e.<a class="code" href="class_gen_i_cam_1_1_generic_exception.html#ac3f2a44c30188d223fac295bd63a9c72">GetDescription</a>() &lt;&lt; endl;</div>
<div class="line">  }</div>
</div><!-- fragment --><p>The code snippets in this section are taken from the <a class="el" href="sample_code.html#sample_ParametrizeCamera_LoadAndSave">ParametrizeCamera_LoadAndSave</a> sample.</p>
<h1><a class="anchor" id="shadingfileio"></a>
Transferring Shading Data to the Camera</h1>
<p>This section describes how to transfer gain shading data to the camera using the GenICam FileIO functionality.</p>
<p>Camera devices supporting the gain shading feature store the shading data as files in the camera's internal file system. These files are accessed using the GenICam <a class="el" href="_filestream_8h.html">Filestream </a> classes provided in the <a class="el" href="_filestream_8h.html" title="Definition of ODevFileStream and IDevFileStream. ">GenApi/Filestream.h</a> header file.</p>
<div class="fragment"><div class="line"><span class="comment">// Include files to use the PYLON API</span></div>
<div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_pylon_includes_8h.html">pylon/PylonIncludes.h</a>&gt;</span></div>
<div class="line"><span class="keyword">using namespace </span>Pylon;</div>
<div class="line"></div>
<div class="line"><span class="comment">// for file upload</span></div>
<div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_filestream_8h.html">GenApi/Filestream.h</a>&gt;</span></div>
<div class="line"></div>
<div class="line">  <span class="comment">// ...</span></div>
<div class="line"></div>
<div class="line">  <span class="comment">// Create the camera object of the first available camera</span></div>
<div class="line">  <span class="comment">// The camera object is used to set and get all available</span></div>
<div class="line">  <span class="comment">// camera features.</span></div>
<div class="line">  Camera_t Camera(pTl-&gt;<a class="code" href="struct_pylon_1_1_i_device_factory.html#a9891f54248fa6dc0f7cab171044458c4">CreateDevice</a>(devices[ 0 ]));</div>
<div class="line"></div>
<div class="line">  <span class="comment">// Open the camera</span></div>
<div class="line">  Camera.Open();</div>
<div class="line"></div>
<div class="line">  <span class="comment">// ...</span></div>
</div><!-- fragment --><p>GenICam defines two char based stream classes for easy to use read and write operations. </p>
<div class="fragment"><div class="line"><span class="keyword">typedef</span> ODevFileStreamBase&lt;char, std::char_traits&lt;char&gt; &gt; ODevFileStream;</div>
<div class="line"><span class="keyword">typedef</span> IDevFileStreamBase&lt;char, std::char_traits&lt;char&gt; &gt; IDevFileStream;</div>
</div><!-- fragment --><p>The <code>ODevFileStream</code> class is used for uploading data to the camera's file system. The <code>IDevFileStream</code> class is used for downloading data from the camera's file system.</p>
<p>Internally, the classes use the <a class="el" href="class_gen_i_cam_1_1_file_protocol_adapter.html">GenICam::FileProtocolAdapter</a> class. The <a class="el" href="class_gen_i_cam_1_1_file_protocol_adapter.html">GenICam::FileProtocolAdapter</a> class defines file based operations like open, close, read, and write.</p>
<p>One common parameter for these operations is the file name of the file to be used on the device file system. The file name must correspond to an existing file in the device file system. To retrieve a list of valid file names supported by the connected camera, read the entries of the "FileSelector" enumeration feature.</p>
<div class="fragment"><div class="line"><a class="code" href="class_gen_api_1_1_c_pointer.html">GenApi::CEnumerationPtr</a> ptrFileSelector = Camera.GetNodeMap().GetNode(<span class="stringliteral">&quot;FileSelector&quot;</span>);</div>
<div class="line"><span class="keywordflow">if</span> ( ptrFileSelector.<a class="code" href="class_gen_api_1_1_c_pointer.html#a5ab02b4f880c9459473bf5db7d3c107f">IsValid</a>() ) {</div>
<div class="line">  <span class="keywordflow">try</span></div>
<div class="line">  {</div>
<div class="line">    <a class="code" href="class_gen_api_1_1node__vector.html">GenApi::NodeList_t</a> entries;</div>
<div class="line">    ptrFileSelector-&gt;GetEntries( entries );</div>
<div class="line">    <span class="keywordflow">for</span> ( GenApi::NodeList_t::iterator it = entries.begin(); it != entries.end(); ++it) {</div>
<div class="line">      <span class="keywordflow">if</span> (<a class="code" href="group___gen_api___public_interface.html#gaf50a08b3955f5d590b690fb25849b602">GenApi::IsAvailable</a>(*it)) {</div>
<div class="line">        <a class="code" href="class_gen_api_1_1_c_pointer.html">GenApi::CEnumEntryPtr</a> pEntry = (*it);</div>
<div class="line">        <span class="keywordflow">if</span> ( NULL != pEntry ) {</div>
<div class="line">          <a class="code" href="struct_gen_api_1_1_i_node.html">GenApi::INode</a>* pNode = pEntry-&gt;GetNode();</div>
<div class="line">          <a class="code" href="class_gen_i_cam_1_1gcstring.html">GenICam::gcstring</a> strFilename = pEntry-&gt;GetSymbolic().c_str();</div>
<div class="line"></div>
<div class="line">          <span class="comment">// Do with strFilename whatever you want (e.g. adding to a list)</span></div>
<div class="line">          <span class="comment">// ...</span></div>
<div class="line"></div>
<div class="line">        } <span class="comment">// if</span></div>
<div class="line">      } <span class="comment">// if</span></div>
<div class="line">    } <span class="comment">// for</span></div>
<div class="line">  }</div>
<div class="line">  <span class="keywordflow">catch</span> (<a class="code" href="class_gen_i_cam_1_1_generic_exception.html">GenICam::GenericException</a> &amp;e)</div>
<div class="line">  {</div>
<div class="line">    <span class="comment">// Handle error</span></div>
<div class="line">    <span class="comment">// ...</span></div>
<div class="line">  }</div>
<div class="line">} <span class="comment">// if</span></div>
</div><!-- fragment --><h2><a class="anchor" id="uploadShadingData"></a>
Upload Shading Data to the Camera</h2>
<p>The camera device stores gain shading data in files named "UserGainShading1", "UserGainShading2", etc.</p>
<p>To upload gain shading data to the camera use the <code>ODevFileStream</code> class.</p>
<div class="fragment"><div class="line"><span class="comment">// Name of the file in the camera where shading data is stored</span></div>
<div class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">char</span> CameraFilename[] = <span class="stringliteral">&quot;UserGainShading1&quot;</span>;</div>
<div class="line"></div>
<div class="line"><span class="comment">// ...</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// Read data from local file into pBuf</span></div>
<div class="line"><span class="keywordtype">char</span> *pBuf = <span class="keyword">new</span> <span class="keywordtype">char</span>[Size];</div>
<div class="line"><span class="keywordtype">size_t</span> read = fread(pBuf, 1, Size, fp);</div>
<div class="line">fclose(fp);</div>
<div class="line"></div>
<div class="line"><span class="keywordflow">if</span> (read != Size) {</div>
<div class="line">    <a class="code" href="group___base___public_impl.html#ga16e6d812cf9af13e0f4106c77689e46b">RUNTIME_EXCEPTION</a>(<span class="stringliteral">&quot;Failed to read from file &#39;%s&#39;\n&quot;</span>, pLocalFilename);</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"><span class="comment">// Transfer data to camera</span></div>
<div class="line">ODevFileStream stream(&amp;Camera.GetNodeMap(), CameraFilename);</div>
<div class="line">stream.write(pBuf, streamsize(Size));</div>
<div class="line"><span class="keywordflow">if</span> (stream.fail()) {</div>
<div class="line">    <span class="comment">// Do some error handling</span></div>
<div class="line">    <span class="comment">// ...</span></div>
<div class="line">}</div>
<div class="line"></div>
<div class="line">stream.close();</div>
<div class="line"><span class="keyword">delete</span>[] pBuf;</div>
<div class="line"></div>
<div class="line"><span class="comment">// ...</span></div>
</div><!-- fragment --><p> This code snippet is taken from the <a class="el" href="sample_code.html#sample_ParametrizeCamera_Shading">ParametrizeCamera_Shading</a> sample program.</p>
<h2><a class="anchor" id="downloadShadingData"></a>
Download Shading Data From the Camera</h2>
<p>Downloading shading data from the camera to a buffer is as simple as uploading shading data.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#define FILEBUFFSIZE 1024   // size of receive buffer!</span></div>
<div class="line"><span class="preprocessor"></span><span class="comment">// Name of the file in the camera where shading data is stored</span></div>
<div class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">char</span> CameraFilename[] = <span class="stringliteral">&quot;UserGainShading1&quot;</span>;</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">char</span> *pBuffer = <span class="keyword">new</span> <span class="keywordtype">char</span>[FILEBUFFSIZE];</div>
<div class="line"></div>
<div class="line"><span class="comment">// ...</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// Transfer data from camera</span></div>
<div class="line">IDevFileStream stream(&amp;Camera.GetNodeMap(), CameraFilename);</div>
<div class="line"><span class="keywordflow">if</span> (stream.fail()) {</div>
<div class="line">  <a class="code" href="group___base___public_impl.html#ga16e6d812cf9af13e0f4106c77689e46b">RUNTIME_EXCEPTION</a>(<span class="stringliteral">&quot;Failed to open camerafile file &#39;%s&#39;\n&quot;</span>, CameraFilename);</div>
<div class="line">}</div>
<div class="line"><span class="keywordtype">int</span> nBytesRead = 0;</div>
<div class="line"><span class="keywordflow">if</span> (stream.is_open()) {</div>
<div class="line">  <span class="keywordflow">do</span> {</div>
<div class="line">    stream.read(pBuffer, FILEBUFFSIZE); <span class="comment">// read max. FILEBUFFSIZE number of bytes from camera</span></div>
<div class="line">    nBytesRead = stream.gcount();     <span class="comment">// get number of bytes read</span></div>
<div class="line">    <span class="keywordflow">if</span> (nBytesRead &gt; 0) {</div>
<div class="line">      <span class="comment">// Do something with the received bytes in pBuffer e.g. writing to disk</span></div>
<div class="line">      <span class="comment">// file.write(pBuffer, nBytesRead);</span></div>
<div class="line">      <span class="comment">// ...</span></div>
<div class="line">    }</div>
<div class="line">  } <span class="keywordflow">while</span> (nBytesRead == FILEBUFFSIZE);   <span class="comment">// if nBytesRead == FILEBUFFSIZE maybe there are more data to receive</span></div>
<div class="line">}</div>
<div class="line"></div>
<div class="line">stream.close();</div>
<div class="line"><span class="keyword">delete</span> [] pBuffer;</div>
</div><!-- fragment --><h1><a class="anchor" id="waitingformultiple"></a>
Waiting for Multiple Events</h1>
<h2><a class="anchor" id="WaitObjects"></a>
Wait Objects</h2>
<p>In applications, a separate thread is often dedicated to grabbing images. Typically, this grab thread must be synchronized with other threads of the application. For example, an application may want to signal the grab thread to terminate.</p>
<p>Synchronization can be realized by using Wait Objects. The concept of Wait Objects introduced in the <a class="el" href="low_level_api.html#RetrievingGrabbedImages">Retrieving Grabbed Images</a> section allows not only waiting until a grabbed buffer is available, but also getting informed about other events.</p>
<p>Wait Objects are an abstraction of operating system specific objects that can be either signaled or non-signaled. Wait Objects provide a wait operation that blocks until the Wait Object is signaled.</p>
<p>While the pylon interfaces return objects of the <a class="el" href="class_pylon_1_1_wait_object.html" title="A platform independent wait object. ">Pylon::WaitObject</a> type, pylon provides the <a class="el" href="class_pylon_1_1_wait_object_ex.html" title="A wait object that the user may signal. ">Pylon::WaitObjectEx</a> class that is to be instantiated by user applications. Use the static factory method <a class="el" href="class_pylon_1_1_wait_object_ex.html#a2366cd73da386f70a5b012a8db4a44be">WaitObjectEx::Create() </a> to create these wait objects.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_pylon_includes_8h.html">pylon/PylonIncludes.h</a>&gt;</span></div>
<div class="line"><span class="keyword">using namespace </span>Pylon;</div>
<div class="line"></div>
<div class="line">  <span class="comment">// ...</span></div>
<div class="line"></div>
<div class="line">  <a class="code" href="class_pylon_1_1_wait_object_ex.html">WaitObjectEx</a> wo( <a class="code" href="class_pylon_1_1_wait_object_ex.html#a2366cd73da386f70a5b012a8db4a44be">WaitObjectEx::Create</a>() );</div>
</div><!-- fragment --><p>The <a class="el" href="class_pylon_1_1_wait_object_ex.html#a33aecdc76a3f2b28f644875781087210">WaitObjectEx::Signal() </a> method is used to signal a wait object. The <a class="el" href="class_pylon_1_1_wait_object_ex.html#abd623b0c249d5c9117304d8375fa4ebf">WaitObjectEx::Reset() </a> method can be used to put the Wait Object into the non-signaled state.</p>
<div class="fragment"><div class="line"><span class="comment">// Put w0 into the signaled state</span></div>
<div class="line">w0.Signal();</div>
<div class="line"></div>
<div class="line"><span class="comment">// Put w0 into the non-signaled state</span></div>
<div class="line">w0.Reset();</div>
</div><!-- fragment --><h2><a class="anchor" id="WaitContainer"></a>
Container for Wait Objects</h2>
<p>The <a class="el" href="class_pylon_1_1_wait_objects.html" title="A set of wait objects. ">Pylon::WaitObjects</a> class is a container for Wait Objects and provides two methods of waiting for Wait Objects stored in the container: </p>
<ul>
<li>The <a class="el" href="class_pylon_1_1_wait_objects.html#a5624256c6bc93ae86be10a29b258d592" title="Wait for any one object to get signaled. ">Pylon::WaitObjects::WaitForAny()</a> method returns when at least one object in the container is signaled. </li>
<li>The <a class="el" href="class_pylon_1_1_wait_objects.html#ab697b680f24fdfee57f595b43d609542" title="Wait for all objects to get signaled. ">Pylon::WaitObjects::WaitForAll()</a> method returns when all objects in the container are signaled.</li>
</ul>
<div class="fragment"><div class="line"><span class="comment">// Create a container and insert two wait objects</span></div>
<div class="line">WaitObjects waitObjects;</div>
<div class="line">waitObjects.Add(w0);</div>
<div class="line">waitObjects.Add(w1);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Wait for three seconds until any of the wait objects get signaled</span></div>
<div class="line"><span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> index;</div>
<div class="line"><span class="keywordflow">if</span> ( waitObjects.WaitForAny( 3000, &amp;index) ) {</div>
<div class="line">  cout &lt;&lt; <span class="stringliteral">&quot;WaitObject w&quot;</span> &lt;&lt; index &lt;&lt; <span class="stringliteral">&quot; has been signaled&quot;</span> &lt;&lt; endl;</div>
<div class="line">}</div>
<div class="line"><span class="keywordflow">else</span> {</div>
<div class="line">  cout &lt;&lt; <span class="stringliteral">&quot;Timeout occurred when waiting for wait objects&quot;</span> &lt;&lt; endl;</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"><span class="comment">// Wait for three seconds until all of the wait objects are signaled</span></div>
<div class="line"><span class="keywordflow">if</span> ( waitObjects.WaitForAll(3000) ) {</div>
<div class="line">  cout &lt;&lt; <span class="stringliteral">&quot;All wait objects are signaled&quot;</span> &lt;&lt; endl;</div>
<div class="line">} <span class="keywordflow">else</span> {</div>
<div class="line">  cout &lt;&lt; <span class="stringliteral">&quot;Timeout occurred when waiting for wait objects&quot;</span> &lt;&lt; endl;</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="WaitExample"></a>
Example</h2>
<p>The following code snippets illustrate how a grab thread uses the <a class="el" href="class_pylon_1_1_wait_objects.html#a5624256c6bc93ae86be10a29b258d592">WaitForAny() </a> method to simultaneously wait for buffers and a termination request.</p>
<p>After preparing for grabbing, the application's main thread starts the grab thread and sleeps for 5 seconds. </p>
<div class="fragment"><div class="line">  <span class="comment">// Start the grab thread. The grab thread starts the image acquisition</span></div>
<div class="line">  <span class="comment">// and grabs images</span></div>
<div class="line">  cout &lt;&lt; <span class="stringliteral">&quot;Going to start the grab thread&quot;</span> &lt;&lt; endl;</div>
<div class="line">  StartThread();</div>
<div class="line"></div>
<div class="line">  <span class="comment">// Let the thread grab images for 5 seconds</span></div>
<div class="line"><span class="preprocessor">#if defined(PYLON_WIN_BUILD)</span></div>
<div class="line"><span class="preprocessor"></span>  Sleep(5000);</div>
<div class="line"><span class="preprocessor">#elif defined(PYLON_LINUX_BUILD)</span></div>
<div class="line"><span class="preprocessor"></span>  sleep(5);</div>
<div class="line"><span class="preprocessor">#else</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">  #error unsupported platform</span></div>
<div class="line"><span class="preprocessor">#endif</span></div>
</div><!-- fragment --><p>The grab thread sets up a Wait Object container holding the StreamGrabber's Wait Object and a <a class="el" href="class_pylon_1_1_wait_object_ex.html" title="A wait object that the user may signal. ">Pylon::WaitObjectEx</a>. The latter is used by the main thread to request the termination of grabbing:</p>
<div class="fragment"><div class="line"><span class="comment">// Create and prepare the wait object container</span></div>
<div class="line">WaitObjects waitObjects;</div>
<div class="line"></div>
<div class="line">waitObjects.Add( Camera.GetGrabResultWaitObject() );  <span class="comment">// Getting informed about grab results</span></div>
<div class="line">waitObjects.Add( m_TerminationEvent ); <span class="comment">// Getting informed about termination request</span></div>
</div><!-- fragment --><p>Then the grab thread enters an infinite loop that starts waiting for any of the Wait Objects:</p>
<div class="fragment"><div class="line">CGrabResultPtr result;   <span class="comment">// Grab result</span></div>
<div class="line"><span class="keywordtype">bool</span> terminate = <span class="keyword">false</span>;</div>
<div class="line"><span class="keywordflow">while</span> ( ! terminate ) {</div>
<div class="line">  <span class="keywordflow">if</span> ( ! waitObjects.WaitForAny( INFINITE, &amp;index ) ) {</div>
<div class="line">    <span class="comment">// Timeout occurred, should never happen when using INFINITE</span></div>
<div class="line">    cerr &lt;&lt; <span class="stringliteral">&quot;Timeout occurred????&quot;</span> &lt;&lt; endl;</div>
<div class="line">    <span class="keywordflow">break</span>;</div>
<div class="line">  }</div>
</div><!-- fragment --><p>When the <a class="el" href="class_pylon_1_1_wait_objects.html#a5624256c6bc93ae86be10a29b258d592">WaitForAny() </a> method returns with true, the value of <code>index</code> is used to determine whether a buffer has been grabbed or a request to terminate grabbing is pending:</p>
<div class="fragment"><div class="line"><span class="keywordflow">switch</span> ( index )</div>
<div class="line">{</div>
<div class="line"><span class="keywordflow">case</span> 0:  <span class="comment">// A grabbed buffer is available</span></div>
<div class="line">  <span class="keywordflow">if</span> ( m_Camera.RetrieveResult( 0, result, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga038e4dd8fbd49dd4e7ec17cc605d1344a957ab0224b24e6361ceea112c5148067">TimeoutHandling_Return</a> ) ) {</div>
<div class="line">    <span class="keywordflow">if</span> ( result-&gt;GrabSucceeded() ) {</div>
<div class="line">      cout &lt;&lt; <span class="stringliteral">&quot;Successfully grabbed image &quot;</span> &lt;&lt; ++nSucc &lt;&lt; endl;</div>
<div class="line">      <span class="keywordtype">unsigned</span> <span class="keywordtype">char</span>* pPixel = (<span class="keywordtype">unsigned</span> <span class="keywordtype">char</span>*) result-&gt;GetBuffer();</div>
<div class="line">      <span class="comment">// Process buffer .....</span></div>
<div class="line">    }</div>
<div class="line">  } <span class="keywordflow">else</span> {</div>
<div class="line">    cerr &lt;&lt; <span class="stringliteral">&quot;Failed to retrieve result&quot;</span> &lt;&lt; endl;</div>
<div class="line">    terminate = <span class="keyword">true</span>;</div>
<div class="line">  }</div>
<div class="line">  <span class="keywordflow">break</span>;</div>
<div class="line"></div>
<div class="line"><span class="keywordflow">case</span> 1:  <span class="comment">// Received a termination request</span></div>
<div class="line">  terminate = <span class="keyword">true</span>;</div>
<div class="line">  <span class="keywordflow">break</span>;</div>
<div class="line">} <span class="comment">// switch</span></div>
</div><!-- fragment --><p>The main thread signals the grab thread to terminate by calling the <code>WaitObjectEx's</code> <a class="el" href="class_pylon_1_1_wait_object_ex.html#a33aecdc76a3f2b28f644875781087210">Signal() </a> method:</p>
<div class="fragment"><div class="line"><span class="comment">// Signal the thread to terminate</span></div>
<div class="line">cout &lt;&lt; <span class="stringliteral">&quot;Going to issue termination request&quot;</span> &lt;&lt; endl;</div>
<div class="line">m_TerminationEvent.Signal();</div>
</div><!-- fragment --><p>Now the main thread can join with the grab thread.</p>
<h2><a class="anchor" id="InterruptibleWait"></a>
Interruptible Wait Operation</h2>
<p>It was demonstrated in the previous section how a <a class="el" href="class_pylon_1_1_wait_object_ex.html" title="A wait object that the user may signal. ">Pylon::WaitObjectEx</a> can be used to signal a thread to terminate.</p>
<p>As an alternative to using dedicated Wait Objects to get informed about external events, the <a class="el" href="class_pylon_1_1_wait_object.html#a68b6d84aed84e7dd53c09a4fb78da7fa">WaitObject::WaitEx() </a> method can be used for waiting. This wait operation can be interrupted. For the Windows version of pylon, <a class="el" href="class_pylon_1_1_wait_object.html#a68b6d84aed84e7dd53c09a4fb78da7fa">WaitEx() </a> can be interrupted by a queued APC or an I/O completion routine. For the Linux version of pylon, <a class="el" href="class_pylon_1_1_wait_object.html#a68b6d84aed84e7dd53c09a4fb78da7fa">WaitEx() </a> can be interrupted by signals.</p>
<p>Example: </p>
<div class="fragment"><div class="line"><span class="keywordtype">bool</span> terminate = <span class="keyword">false</span>;  <span class="comment">// Will be set to true when a signal has been detected</span></div>
<div class="line"><span class="comment">// Grab images until we get a signal</span></div>
<div class="line"><span class="keywordflow">while</span> ( ! terminate ) {</div>
<div class="line">  <span class="comment">// Wait for the grabbed image with timeout of 10 seconds. We want to be interruptible by signals.</span></div>
<div class="line">  waitex_result_t waitResult = StreamGrabber.GetWaitObject().WaitEx(10000, <span class="keyword">true</span>);</div>
<div class="line">  <span class="keywordflow">switch</span> ( waitResult )</div>
<div class="line">  {</div>
<div class="line">  <span class="keywordflow">case</span> <a class="code" href="namespace_pylon.html#a538b1d4292c8bc01c03d70952d365249a79103e30dda39bbb8ce87086895b948f">waitex_timeout</a>:  <span class="comment">// Timeout occurred, no buffer available</span></div>
<div class="line">    {</div>
<div class="line">      cerr &lt;&lt; <span class="stringliteral">&quot;Failed to grab image: timout&quot;</span> &lt;&lt; endl;</div>
<div class="line">      <span class="keywordflow">continue</span>;</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">  <span class="keywordflow">case</span> <a class="code" href="namespace_pylon.html#a538b1d4292c8bc01c03d70952d365249a1149c570bcbc84378d19f7317968b7ef">waitex_signaled</a>:  <span class="comment">// Buffer is available in the driver&#39;s output queue</span></div>
<div class="line">    {</div>
<div class="line">      <span class="comment">// Get the grab result</span></div>
<div class="line">      GrabResult Result;</div>
<div class="line">      StreamGrabber.RetrieveResult(Result);</div>
<div class="line"></div>
<div class="line">      <span class="keywordflow">if</span> (<a class="code" href="group___pylon___low_level_api.html#gga4afc5255837dea09eb304a583f0c9231abaa28d8ce6fd0b48ada460db0817ff07">Grabbed</a> == Result.Status()) {</div>
<div class="line">        <span class="comment">// Grabbing was successful, process image</span></div>
<div class="line">        cout &lt;&lt; <span class="stringliteral">&quot;.&quot;</span> &lt;&lt; flush;</div>
<div class="line">      } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (<a class="code" href="group___pylon___low_level_api.html#gga4afc5255837dea09eb304a583f0c9231a828c1f21b5fa8cfdd2e93c766484c808">Failed</a> == Result.Status())</div>
<div class="line">      {</div>
<div class="line">        <span class="comment">// Error Handling</span></div>
<div class="line">        cerr &lt;&lt; <span class="stringliteral">&quot;Failed to acquire image!&quot;</span> &lt;&lt; endl;</div>
<div class="line">        cerr &lt;&lt; <span class="stringliteral">&quot;Error code : 0x&quot;</span> &lt;&lt; hex</div>
<div class="line">          &lt;&lt; Result.GetErrorCode() &lt;&lt; endl;</div>
<div class="line">        cerr &lt;&lt; <span class="stringliteral">&quot;Error description : &quot;</span></div>
<div class="line">          &lt;&lt; Result.GetErrorDescription() &lt;&lt; endl;</div>
<div class="line">      }</div>
<div class="line"></div>
<div class="line">      <span class="comment">// Reuse the buffer for grabbing the next image</span></div>
<div class="line">      StreamGrabber.QueueBuffer(Result.Handle(), NULL);</div>
<div class="line">      <span class="keywordflow">break</span>;</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">  <span class="keywordflow">case</span> <a class="code" href="namespace_pylon.html#a538b1d4292c8bc01c03d70952d365249a810470fa9eb0178dc0df56acf80610ce">waitex_alerted</a>:  <span class="comment">// Wait operation has been interrupted by a signal</span></div>
<div class="line">    {</div>
<div class="line">      cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">&quot;Got signal. Terminating application&quot;</span> &lt;&lt; endl;</div>
<div class="line">      terminate = <span class="keyword">true</span>;</div>
<div class="line">      <span class="keywordflow">break</span>;</div>
<div class="line">    }</div>
<div class="line">  } <span class="comment">// switch</span></div>
<div class="line">} <span class="comment">// while</span></div>
</div><!-- fragment --><p>This code snippet has been taken from the WaitEx sample that comes with the pylon for Linux SDK.</p>
<p>Corresponding to the <a class="el" href="class_pylon_1_1_wait_object.html#a68b6d84aed84e7dd53c09a4fb78da7fa">WaitObject::WaitEx() </a> method, the <a class="el" href="class_pylon_1_1_wait_objects.html" title="A set of wait objects. ">Pylon::WaitObjects</a> class provides the interruptable <a class="el" href="class_pylon_1_1_wait_objects.html#adec54801c4f9263b4821109ca4f87139">WaitForAnyEx() </a> and <a class="el" href="class_pylon_1_1_wait_objects.html#ab428b0df6dcaae482c78ac6c2f551163">WaitForAllEx() </a> methods.</p>
<h1><a class="anchor" id="highperformanceapps"></a>
Application Settings for High Performance</h1>
<p>The following settings are recommended for applications that require image processing at a constant frame rate and with low jitter:</p>
<ul>
<li>The packet size should be adjusted to the highest value supported by your network adapter and network setup, e.g. to a packet size of 8092 bytes. </li>
<li>The grab loop thread should have its priority set to a value in the real-time priority range. The grab loop thread is the thread that calls the RetrieveResult() method. A value of 24 or higher is recommended. Thread priorities can be adjusted using the <a class="el" href="namespace_pylon.html#ab5955fe2bfdfc50177659c49ae90e854"><code>SetRTThreadPriority</code> </a> method. The priority of the grab loop thread that is optionally provided by the Instant Camera object can be adjusted using the <a class="el" href="class_basler___instant_camera_params_1_1_c_instant_camera_params___params.html#a6159c1bb1eec6e3e71fe5afe392559ae"><code>GrabLoopThreadPriorityOverride</code> </a> and <a class="el" href="class_basler___instant_camera_params_1_1_c_instant_camera_params___params.html#ad7083601ed31e4e8a727e24c60ea3800"><code>GrabLoopThreadPriority</code> </a> parameters. </li>
<li>The internal Instant Camera grab engine thread should have its priority set to a value in the real-time priority range. A value of 25 or higher is recommended. The default priority is 25. The grab engine thread priority must be higher than the grab loop thread priority. The grab engine thread priority can be adjusted using the <a class="el" href="class_basler___instant_camera_params_1_1_c_instant_camera_params___params.html#a0efa8f1c78b0784b3b7ac3e946f5c5db"><code>InternalGrabEngineThreadPriorityOverride</code> </a> and <a class="el" href="class_basler___instant_camera_params_1_1_c_instant_camera_params___params.html#a5e592c3eae8b86efc116bba89805cd95"><code>InternalGrabEngineThreadPriority</code> </a> parameters.</li>
</ul>
<dl class="section note"><dt>Note</dt><dd>When using real-time thread priorities, be very careful to ensure that no high-priority thread consumes all of the available CPU time.</dd></dl>
<h1><a class="anchor" id="programmers_guide_low_level_api"></a>
Programming Using the pylon Low Level API</h1>
<p>The Instant Camera classes use the Low Level API for operation. That means that the previous API, now called the Low Level API, is still part of the pylon C++ API and will be in the future. The Low Level API can be used for existing applications and for rare highly advanced use cases that cannot be covered using the Instant Camera classes. More information about how to program using the Low Level API can be found <a class="el" href="low_level_api.html">here</a>.</p>
<h1><a class="anchor" id="migration_to_usb"></a>
Migrating Existing Code for Using USB Camera Devices</h1>
<h2><a class="anchor" id="sfnc_parameter_name_changes"></a>
Changes of Parameter Names and Behavior</h2>
<p>Features, like 'Gain', are named according to the <a class="el" href="pylon_advanced_topics.html#GenApiNodeMaps">GenICam</a> Standard Feature Naming Convention (SFNC). The SFNC defines a common set of features, their behavior, and the related parameter names. This ensures the interoperability of cameras from different camera vendors. Cameras compliant with the USB3 Vision standard are based on the SFNC version 2.0. Basler GigE and Firewire cameras are based on previous SFNC versions. Accordingly, the behavior of these cameras and some parameters names will be different.</p>
<h3><a class="anchor" id="sfnc_parameter_name_changes_sfnc_version"></a>
SFNC Version Handling</h3>
<p>If your code has to work with multiple camera device types that are compatible with different SFNC versions, you can use the <a class="el" href="class_pylon_1_1_c_instant_camera.html#a90d2817d90e2a6b0a2fa120666bc702a">GetSfncVersion() </a> method to handle differences in parameter name and behavior.</p>
<p>Example for <a class="el" href="pylon_programmingguide.html#generic_parameter_access">Generic Parameter Access</a> :</p>
<div class="fragment"><div class="line"><span class="comment">// Check to see which Standard Feature Naming Convention (SFNC) is used by the camera device.</span></div>
<div class="line"><span class="keywordflow">if</span> ( camera.GetSfncVersion() &gt;= Sfnc_2_0_0)</div>
<div class="line">{</div>
<div class="line">    <span class="comment">// Access the Gain float type node. This node is available for USB camera devices.</span></div>
<div class="line">    <span class="comment">// USB camera devices are compliant to SFNC version 2.0.</span></div>
<div class="line">    CFloatPtr gain( nodemap.GetNode( <span class="stringliteral">&quot;Gain&quot;</span>));</div>
<div class="line">    <span class="keywordtype">double</span> newGain = gain-&gt;GetMin() + ((gain-&gt;GetMax() - gain-&gt;GetMin()) / 2);</div>
<div class="line">    gain-&gt;SetValue(newGain);</div>
<div class="line">    cout &lt;&lt; <span class="stringliteral">&quot;Gain (50%)       : &quot;</span> &lt;&lt; gain-&gt;GetValue() &lt;&lt; <span class="stringliteral">&quot; (Min: &quot;</span> &lt;&lt; gain-&gt;GetMin() &lt;&lt; <span class="stringliteral">&quot;; Max: &quot;</span> &lt;&lt; gain-&gt;GetMax() &lt;&lt; <span class="stringliteral">&quot;)&quot;</span> &lt;&lt; endl;</div>
<div class="line">}</div>
<div class="line"><span class="keywordflow">else</span></div>
<div class="line">{</div>
<div class="line">    <span class="comment">// Access the GainRaw integer type node. This node is available for IIDC 1394 and GigE camera devices.</span></div>
<div class="line">    <a class="code" href="group___gen_api___public_utilities.html#gaf688b006c4c1c4c568e85dda02f44280">CIntegerPtr</a> gainRaw( nodemap.GetNode( <span class="stringliteral">&quot;GainRaw&quot;</span>));</div>
<div class="line">    int64_t newGainRaw = gainRaw-&gt;GetMin() + ((gainRaw-&gt;GetMax() - gainRaw-&gt;GetMin()) / 2);</div>
<div class="line">    <span class="comment">// Make sure the calculated value is valid.</span></div>
<div class="line">    newGainRaw = Adjust(newGainRaw, gainRaw-&gt;GetMin(), gainRaw-&gt;GetMax(), gainRaw-&gt;GetInc());</div>
<div class="line">    gainRaw-&gt;SetValue(newGainRaw);</div>
<div class="line">    cout &lt;&lt; <span class="stringliteral">&quot;Gain (50%)       : &quot;</span> &lt;&lt; gainRaw-&gt;GetValue() &lt;&lt; <span class="stringliteral">&quot; (Min: &quot;</span> &lt;&lt; gainRaw-&gt;GetMin() &lt;&lt; <span class="stringliteral">&quot;; Max: &quot;</span> &lt;&lt; gainRaw-&gt;GetMax() &lt;&lt; <span class="stringliteral">&quot;; Inc: &quot;</span> &lt;&lt; gainRaw-&gt;GetInc() &lt;&lt; <span class="stringliteral">&quot;)&quot;</span> &lt;&lt; endl;</div>
<div class="line">}</div>
</div><!-- fragment --><p>Conditional compilation can be used to handle differences in parameter name and behavior when using <a class="el" href="pylon_programmingguide.html#native_parameter_access">Native Parameter Access</a> :</p>
<div class="fragment"><div class="line"><span class="preprocessor">#ifdef USE_USB</span></div>
<div class="line"><span class="preprocessor"></span>        <span class="keywordtype">double</span> newGain = camera.Gain.GetMin() + ((camera.Gain.GetMax() - camera.Gain.GetMin()) / 2);</div>
<div class="line">        camera.Gain.SetValue(newGain);</div>
<div class="line">        cout &lt;&lt; <span class="stringliteral">&quot;Gain (50%)       : &quot;</span> &lt;&lt; camera.Gain.GetValue() &lt;&lt; <span class="stringliteral">&quot; (Min: &quot;</span> &lt;&lt; camera.Gain.GetMin() &lt;&lt; <span class="stringliteral">&quot;; Max: &quot;</span> &lt;&lt; camera.Gain.GetMax() &lt;&lt; <span class="stringliteral">&quot;)&quot;</span> &lt;&lt; endl;</div>
<div class="line"><span class="preprocessor">#else</span></div>
<div class="line"><span class="preprocessor"></span>        int64_t newGainRaw = camera.GainRaw.GetMin() + ((camera.GainRaw.GetMax() - camera.GainRaw.GetMin()) / 2);</div>
<div class="line">        <span class="comment">// Make sure the calculated value is valid</span></div>
<div class="line">        newGainRaw = Adjust(newGainRaw, camera.GainRaw.GetMin(), camera.GainRaw.GetMax(), camera.GainRaw.GetInc());</div>
<div class="line">        camera.GainRaw.SetValue(newGainRaw);</div>
<div class="line">        cout &lt;&lt; <span class="stringliteral">&quot;Gain (50%)       : &quot;</span> &lt;&lt; camera.GainRaw.GetValue() &lt;&lt; <span class="stringliteral">&quot; (Min: &quot;</span> &lt;&lt; camera.GainRaw.GetMin() &lt;&lt; <span class="stringliteral">&quot;; Max: &quot;</span> &lt;&lt; camera.GainRaw.GetMax() &lt;&lt; <span class="stringliteral">&quot;; Inc: &quot;</span> &lt;&lt; camera.GainRaw.GetInc() &lt;&lt; <span class="stringliteral">&quot;)&quot;</span> &lt;&lt; endl;</div>
<div class="line"><span class="preprocessor">#endif</span></div>
</div><!-- fragment --><h3><a class="anchor" id="sfnc_parameter_name_changes_table"></a>
List of Changes</h3>
<p>The following tables show how to map previous parameter names to their equivalents defined in SFNC 2.0. Some previous parameters have no direct equivalents. There are previous parameters, however, that can still be accessed using the so-called <a class="el" href="struct_gen_api_1_1_i_node.html#a914b295d26a33f00e9752ae8dde96933">alias </a>. The alias is another representation of the original parameter. Usually the alias provides an Integer representation of a Float parameter.</p>
<p>The following code snippet shows how to get the alias:</p>
<dl class="section attention"><dt>Attention</dt><dd>The alias does not provide a proper name, display name, tool tip, or description. The value range of an alias node can change when updating the camera firmware.</dd></dl>
<div class="fragment"><div class="line"><span class="comment">// Get the alias node of a parameter.</span></div>
<div class="line"><span class="comment">// The alias is another representation of the original parameter.</span></div>
<div class="line"><a class="code" href="class_gen_api_1_1_c_float_ptr.html">GenApi::CFloatPtr</a> gain( camera.GetNodeMap().GetNode( <span class="stringliteral">&quot;Gain&quot;</span>));</div>
<div class="line"><a class="code" href="class_gen_api_1_1_c_pointer.html">GenApi::CIntegerPtr</a> gainRaw;</div>
<div class="line"><span class="keywordflow">if</span> ( gain.IsValid())</div>
<div class="line">{</div>
<div class="line">    <span class="comment">// Get the integer representation of Gain.</span></div>
<div class="line">    <span class="comment">// The alias does not provide a proper name, display name, tool tip, or description.</span></div>
<div class="line">    <span class="comment">// The value range of an alias node can change when updating the camera firmware.</span></div>
<div class="line">    gainRaw = gain-&gt;GetNode()-&gt;GetAlias();</div>
<div class="line">}</div>
</div><!-- fragment --><p>The following table shows how to map changes for parameters:</p>
<dl class="section attention"><dt>Attention</dt><dd>The actual changes between previous cameras and SFNC 2.0 compliant cameras depend on the used models and the used camera firmware versions. It is possible that changes are not listed in the tables below. Other sources of information regarding changes between camera models are the Camera User's Manuals or the information shown in the Pylon Viewer tool.</dd></dl>
<table  border="1" class="table" frame="void" cellspacing="6" cellpadding="7">
<tr>
<th>Previous Parameter Name </th><th>SFNC 2.0 Equivalent </th><th>Parameter Type </th><th>Comments  </th></tr>
<tr>
<td>AcquisitionFrameCount </td><td>AcquisitionBurstFrameCount </td><td>Integer </td><td></td></tr>
<tr>
<td>AcquisitionFrameRateAbs </td><td>AcquisitionFrameRate </td><td>Float </td><td></td></tr>
<tr>
<td>AcquisitionStartEventFrameID </td><td>EventFrameBurstStartFrameID </td><td>Integer </td><td></td></tr>
<tr>
<td>AcquisitionStartEventTimestamp </td><td>EventFrameBurstStartTimestamp </td><td>Integer </td><td></td></tr>
<tr>
<td>AcquisitionStartOvertriggerEventFrameID </td><td>EventFrameBurstStartOvertriggerFrameID </td><td>Integer </td><td></td></tr>
<tr>
<td>AcquisitionStartOvertriggerEventTimestamp </td><td>EventFrameBurstStartOvertriggerTimestamp </td><td>Integer </td><td></td></tr>
<tr>
<td>AutoExposureTimeAbsLowerLimit </td><td>AutoExposureTimeLowerLimit </td><td>Float </td><td></td></tr>
<tr>
<td>AutoExposureTimeAbsUpperLimit </td><td>AutoExposureTimeUpperLimit </td><td>Float </td><td></td></tr>
<tr>
<td>AutoFunctionAOIUsageIntensity </td><td>AutoFunctionAOIUseBrightness </td><td>Boolean </td><td></td></tr>
<tr>
<td>AutoFunctionAOIUsageWhiteBalance </td><td>AutoFunctionAOIUseWhiteBalance </td><td>Boolean </td><td></td></tr>
<tr>
<td>AutoGainRawLowerLimit </td><td>Alias of AutoGainLowerLimit </td><td>Integer </td><td></td></tr>
<tr>
<td>AutoGainRawUpperLimit </td><td>Alias of AutoGainUpperLimit </td><td>Integer </td><td></td></tr>
<tr>
<td>AutoTargetValue </td><td>Alias of AutoTargetBrightness </td><td>Integer </td><td></td></tr>
<tr>
<td>BalanceRatioAbs </td><td>BalanceRatio </td><td>Float </td><td></td></tr>
<tr>
<td>BalanceRatioRaw </td><td>Alias of BalanceRatio </td><td>Integer </td><td></td></tr>
<tr>
<td>BlackLevelAbs </td><td>BlackLevel </td><td>Float </td><td></td></tr>
<tr>
<td>BlackLevelRaw </td><td>Alias of BlackLevel </td><td>Integer </td><td></td></tr>
<tr>
<td>ChunkExposureTimeRaw </td><td></td><td>Integer </td><td>ChunkExposureTimeRaw has been replaced with ChunkExposureTime. ChunkExposureTime is of type float.  </td></tr>
<tr>
<td>ChunkFrameCounter </td><td></td><td>Integer </td><td>ChunkFrameCounter has been replaced with ChunkCounterSelector and ChunkCounterValue.  </td></tr>
<tr>
<td>ChunkGainAll </td><td></td><td>Integer </td><td>ChunkGainAll has been replaced with ChunkGain. ChunkGain is of type float.  </td></tr>
<tr>
<td>ColorAdjustmentEnable </td><td></td><td>Boolean </td><td>ColorAdjustmentEnable has been removed. The color adjustment is always enabled.  </td></tr>
<tr>
<td>ColorAdjustmentHueRaw </td><td>Alias of ColorAdjustmentHue </td><td>Integer </td><td></td></tr>
<tr>
<td>ColorAdjustmentReset </td><td></td><td>Command </td><td>ColorAdjustmentReset has been removed.  </td></tr>
<tr>
<td>ColorAdjustmentSaturationRaw </td><td>Alias of ColorAdjustmentSaturation </td><td>Integer </td><td></td></tr>
<tr>
<td>ColorTransformationValueRaw </td><td>Alias of ColorTransformationValue </td><td>Integer </td><td></td></tr>
<tr>
<td>DefaultSetSelector </td><td></td><td>Enumeration </td><td>See additional entries in UserSetSelector.  </td></tr>
<tr>
<td>ExposureEndEventFrameID </td><td>EventExposureEndFrameID </td><td>Integer </td><td></td></tr>
<tr>
<td>ExposureEndEventTimestamp </td><td>EventExposureEndTimestamp </td><td>Integer </td><td></td></tr>
<tr>
<td>ExposureTimeAbs </td><td>ExposureTime </td><td>Float </td><td></td></tr>
<tr>
<td>ExposureTimeRaw </td><td>Alias of ExposureTime </td><td>Integer </td><td></td></tr>
<tr>
<td>FrameStartEventFrameID </td><td>EventFrameStartFrameID </td><td>Integer </td><td></td></tr>
<tr>
<td>FrameStartEventTimestamp </td><td>EventFrameStartTimestamp </td><td>Integer </td><td></td></tr>
<tr>
<td>FrameStartOvertriggerEventFrameID </td><td>EventFrameStartOvertriggerFrameID </td><td>Integer </td><td></td></tr>
<tr>
<td>FrameStartOvertriggerEventTimestamp </td><td>EventFrameStartOvertriggerTimestamp </td><td>Integer </td><td></td></tr>
<tr>
<td>GainAbs </td><td>Gain </td><td>Float </td><td></td></tr>
<tr>
<td>GainRaw </td><td>Alias of Gain </td><td>Integer </td><td></td></tr>
<tr>
<td>GammaEnable </td><td></td><td>Boolean </td><td>GammaEnable has been removed. Gamma is always enabled.  </td></tr>
<tr>
<td>GammaSelector </td><td></td><td>Enumeration </td><td>The sRGB setting is automatically applied when LineSourcePreset is set to any other value than Off.  </td></tr>
<tr>
<td>GlobalResetReleaseModeEnable </td><td></td><td>Boolean </td><td>GlobalResetReleaseModeEnable has been replaced with the enumeration ShutterMode.  </td></tr>
<tr>
<td>LightSourceSelector </td><td>LightSourcePreset </td><td>Enumeration </td><td></td></tr>
<tr>
<td>LineDebouncerTimeAbs </td><td>LineDebouncerTime </td><td>Float </td><td></td></tr>
<tr>
<td>MinOutPulseWidthAbs </td><td>LineMinimumOutputPulseWidth </td><td>Float </td><td></td></tr>
<tr>
<td>MinOutPulseWidthRaw </td><td>Alias of LineMinimumOutputPulseWidth </td><td>Integer </td><td></td></tr>
<tr>
<td>ParameterSelector </td><td>RemoveParameterLimitSelector </td><td>Enumeration </td><td></td></tr>
<tr>
<td>ProcessedRawEnable </td><td></td><td>Boolean </td><td>ProcessedRawEnable has been removed because it is not needed anymore. The camera uses nondestructive Bayer demosaicing now.  </td></tr>
<tr>
<td>ReadoutTimeAbs </td><td>SensorReadoutTime </td><td>Float </td><td></td></tr>
<tr>
<td>ResultingFrameRateAbs </td><td>ResultingFrameRate </td><td>Float </td><td></td></tr>
<tr>
<td>TimerDelayAbs </td><td>TimerDelay </td><td>Float </td><td></td></tr>
<tr>
<td>TimerDelayRaw </td><td>Alias of TimerDelay </td><td>Integer </td><td></td></tr>
<tr>
<td>TimerDelayTimebaseAbs </td><td></td><td>Float </td><td>The time base is always 1us.  </td></tr>
<tr>
<td>TimerDurationAbs </td><td>TimerDuration </td><td>Float </td><td></td></tr>
<tr>
<td>TimerDurationRaw </td><td>Alias of TimerDuration </td><td>Integer </td><td></td></tr>
<tr>
<td>TimerDurationTimebaseAbs </td><td></td><td>Float </td><td>The time base is always 1us.  </td></tr>
<tr>
<td>TriggerDelayAbs </td><td>TriggerDelay </td><td>Float </td><td></td></tr>
<tr>
<td>UserSetDefaultSelector </td><td>UserSetDefault </td><td>Enumeration </td><td></td></tr>
</table>
<p>The following table shows how to map changes for enumeration values:</p>
<table  border="1" class="table" frame="void" cellspacing="6" cellpadding="7">
<tr>
<th>Previous Enumeration Name </th><th>Previous Enumeration Value Name </th><th>Value Name SFNC 2.0 </th><th>Comments  </th></tr>
<tr>
<td>AcquisitionStatusSelector </td><td>AcquisitionTriggerWait </td><td>FrameBurstTriggerWait </td><td></td></tr>
<tr>
<td>AutoFunctionProfile </td><td>ExposureMinimum </td><td>MinimizeExposureTime </td><td></td></tr>
<tr>
<td>AutoFunctionProfile </td><td>GainMinimum </td><td>MinimizeGain </td><td></td></tr>
<tr>
<td>ChunkSelector </td><td>GainAll </td><td>Gain </td><td>The gain value is reported via the ChunkGain node as float.  </td></tr>
<tr>
<td>ChunkSelector </td><td>Height </td><td></td><td>Height is part of the image information regardless of the chunk mode setting.  </td></tr>
<tr>
<td>ChunkSelector </td><td>OffsetX </td><td></td><td>OffsetX is part of the image information regardless of the chunk mode setting.  </td></tr>
<tr>
<td>ChunkSelector </td><td>OffsetY </td><td></td><td>OffsetY is part of the image information regardless of the chunk mode setting.  </td></tr>
<tr>
<td>ChunkSelector </td><td>PixelFormat </td><td></td><td>PixelFormat is part of the image information regardless of the chunk mode setting.  </td></tr>
<tr>
<td>ChunkSelector </td><td>Stride </td><td></td><td>Stride is part of the image information regardless of the chunk mode setting.  </td></tr>
<tr>
<td>ChunkSelector </td><td>Width </td><td></td><td>Width is part of the image information regardless of the chunk mode setting.  </td></tr>
<tr>
<td>EventNotification </td><td>GenICamEvent </td><td>On </td><td></td></tr>
<tr>
<td>EventSelector </td><td>AcquisitionStartOvertrigger </td><td>FrameBurstStartOvertrigger </td><td></td></tr>
<tr>
<td>EventSelector </td><td>AcquisitionStart </td><td>FrameBurstStart </td><td></td></tr>
<tr>
<td>LightSourceSelector </td><td>Daylight </td><td>Daylight5000K </td><td></td></tr>
<tr>
<td>LightSourceSelector </td><td>Tungsten </td><td>Tungsten2800K </td><td></td></tr>
<tr>
<td>LineSelector </td><td>Out1 </td><td></td><td>The operation mode of an I/O-Pin is chosen using the LineMode Selector.  </td></tr>
<tr>
<td>LineSelector </td><td>Out2 </td><td></td><td>The operation mode of an I/O-Pin is chosen using the LineMode Selector.  </td></tr>
<tr>
<td>LineSelector </td><td>Out3 </td><td></td><td>The operation mode of an I/O-Pin is chosen using the LineMode Selector.  </td></tr>
<tr>
<td>LineSelector </td><td>Out4 </td><td></td><td>The operation mode of an I/O-Pin is chosen using the LineMode Selector.  </td></tr>
<tr>
<td>LineSource </td><td>AcquisitionTriggerWait </td><td>FrameBurstTriggerWait </td><td></td></tr>
<tr>
<td>LineSource </td><td>UserOutput </td><td></td><td>Use UserOutput1, UserOutput2, or UserOutput3 etc. instead.  </td></tr>
<tr>
<td>PixelFormat </td><td>BayerBG12Packed </td><td></td><td>The pixel format BayerBG12p is provided by USB camera devices. The memory layout of pixel format BayerBG12Packed and pixel format BayerBG12p is different. See the camera User's Manuals for more information on pixel formats.  </td></tr>
<tr>
<td>PixelFormat </td><td>BayerGB12Packed </td><td></td><td>The pixel format BayerGB12p is provided by USB camera devices. The memory layout of pixel format BayerGB12Packed and pixel format BayerGB12p is different. See the camera User's Manuals for more information on pixel formats.  </td></tr>
<tr>
<td>PixelFormat </td><td>BayerGR12Packed </td><td></td><td>The pixel format BayerGR12p is provided by USB camera devices. The memory layout of pixel format BayerGR12Packed and pixel format BayerGR12p is different. See the camera User's Manuals for more information on pixel formats.  </td></tr>
<tr>
<td>PixelFormat </td><td>BayerRG12Packed </td><td></td><td>The pixel format BayerRG12p is provided by USB camera devices. The memory layout of pixel format BayerRG12Packed and pixel format BayerRG12p is different. See the camera User's Manuals for more information on pixel formats.  </td></tr>
<tr>
<td>PixelFormat </td><td>BGR10Packed </td><td>BGR10 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>BGR12Packed </td><td>BGR12 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>BGR8Packed </td><td>BGR8 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>BGRA8Packed </td><td>BGRa8 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>Mono10Packed </td><td></td><td>The pixel format Mono10p is provided by USB camera devices. The memory layout of pixel format Mono10Packed and pixel format Mono10p is different. See the camera User's Manuals for more information on pixel formats.  </td></tr>
<tr>
<td>PixelFormat </td><td>Mono12Packed </td><td></td><td>The pixel format Mono12p is provided by USB camera devices. The memory layout of pixel format Mono12Packed and pixel format Mono12p is different. See the camera User's Manuals for more information on pixel formats.  </td></tr>
<tr>
<td>PixelFormat </td><td>Mono1Packed </td><td>Mono1p </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>Mono2Packed </td><td>Mono2p </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>Mono4Packed </td><td>Mono4p </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>RGB10Packed </td><td>RGB10 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>RGB12Packed </td><td>RGB12 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>RGB16Packed </td><td>RGB16 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>RGB8Packed </td><td>RGB8 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>RGBA8Packed </td><td>RGBa8 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>YUV411Packed </td><td>YCbCr411_8 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>YUV422_YUYV_Packed </td><td>YCbCr422_8 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>YUV444Packed </td><td>YCbCr8 </td><td></td></tr>
<tr>
<td>TriggerSelector </td><td>AcquisitionStart </td><td>FrameBurstStart </td><td></td></tr>
</table>
<h2><a class="anchor" id="usb_changes_transport"></a>
Differences in Image Transport</h2>
<p>The image transport of USB camera devices and Firewire or GigE camera devices is different. Firewire and GigE camera devices automatically send image data to the PC when available. If the PC is not ready to receive the image data because no grab buffer is available, the image data sent by the camera device is dropped. For USB camera devices the PC has to actively request the image data. Grabbed images are stored in the frame buffer of the USB camera device until the PC requests the image data. If the frame buffer of the USB camera device is full, newly acquired frames will be dropped. Old images in the frame buffer of the USB camera device will be grabbed first the next time the PC requests image data. After that, newly acquired images are grabbed.</p>
<h2><a class="anchor" id="usb_strategy_upcoming_image_not_available"></a>
The Grab Strategy Upcoming Image is Not Available For USB Camera Devices</h2>
<p>The Upcoming Image grab strategy uses the effect that images are automatically dropped, if no buffer is available (queued) on the PC when using GigE or Firewire cameras. USB camera devices work differently as described above. Old images can still be stored in the frame buffer of the USB camera device. That's why the Upcoming Image strategy cannot be used for USB camera devices. An exception will be thrown, if a USB camera device is used together with the Upcoming Image grab strategy.</p>
<h2><a class="anchor" id="usb_and_counters"></a>
USB Camera Devices and Block ID</h2>
<p>Image data is transferred between a PC and a USB camera device using a certain sequence of data packets. In the rare case of an error during the image transport, the image data stream between PC and USB camera device is reset automatically, e.g. if the image packet sequence is out of sync. The image data stream reset causes the Block ID delivered by the USB camera device to start again at zero. Pylon indicates this error condition by setting the <a class="el" href="class_pylon_1_1_c_grab_result_data.html#ae26269c7f9c2c848dad24eea33fed0fd">Block ID </a> of the grab result to its highest possible value (UINT64_MAX) for all subsequent grab results. A Block ID of UINT64_MAX is invalid and cannot be used in any further operations. The image data and other grab result data are not affected by the Block ID being invalid. The grabbing needs to be <a class="el" href="class_pylon_1_1_c_instant_camera.html#a5ef34cbfa61d4f0c2c1739bea5e5ee4f">stopped </a> and <a class="el" href="class_pylon_1_1_c_instant_camera.html#a386b84c29f9ee7ec3646fbfbf70236ed">restarted </a> to recover from this error condition if the application uses the Block ID. The Block ID starts at zero if the grabbing is restarted.</p>
<dl class="section note"><dt>Note</dt><dd>Applications that are still using the Low Level API can use the <a class="el" href="struct_pylon_1_1_i_stream_grabber.html#a802212e61c56b1b824c4e5612656f056" title="Cancels pending requests. ">Pylon::IStreamGrabber::CancelGrab</a> method. Calling CancelGrab resets the image stream between PC and USB camera device, too. Therefore, the value of the Block ID is set to UINT64_MAX for all subsequent grab results after calling CancelGrab. </dd></dl>
</div></div><!-- contents -->
<hr><address><small>
&copy;&nbsp;2006-2014&nbsp;<a href="http://www.baslerweb.com/">Basler</a>   (Tue Jul 22 2014 11:41:22)</small></address>
</body>
</html>
